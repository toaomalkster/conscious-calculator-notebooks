{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NumberAdder-0.5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN7Q8H6QD7Jj4VwINrGjKcQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toaomalkster/conscious-calculator-notebooks/blob/main/src/scratch/notebooks/number-adder/NumberAdder_0_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7LX96lpBYkT"
      },
      "source": [
        "# Number Adder\n",
        "0.5:\n",
        "* Continuation of a re-inforcement style loss function across looped model:\n",
        "  * Input presented only on first iteration\n",
        "  * Has 'status' output nodes\n",
        "  * Loss measures ability to produce a >1.0 status with a correct result.\n",
        "\n",
        "## Background\n",
        "Building up towards a model based on Consciousness V2 theory.\n",
        "\n",
        "## Loss Function Considerations\n",
        "Non-negotiables:\n",
        "* Must produce the correct result at some point\n",
        "* Must not falsely represent the result -- ie: if there is a 'completion' flag, then it must always be close to zero if not outputting the result\n",
        "\n",
        "Fuzzy requirements:\n",
        "* Accuracy is more important than efficiency\n",
        "* Needs to identify 'completion' somehow\n",
        "\n",
        "Ideal optimisation requirements:\n",
        "* Minimise effort to produce result\n",
        "  * Optimises for quicker response times\n",
        "  * Also a protection against infinite loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL5HKtzQRHWg"
      },
      "source": [
        "**App Boilerplate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ruY3TtqP1gb",
        "outputId": "d39038ff-54ff-4fea-87b5-240a3650cbc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuRO0frKRXNG"
      },
      "source": [
        "# Setup Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9uKG-DgmzBj",
        "outputId": "5762f2a4-0d42-4e38-b33f-34922fd157ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "data = np.random.randint(100, size=(1000, 2)).astype('float32')\n",
        "data[0:10,:]"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5., 77.],\n",
              "       [ 1., 87.],\n",
              "       [41.,  0.],\n",
              "       [62., 82.],\n",
              "       [15., 16.],\n",
              "       [96.,  3.],\n",
              "       [56., 93.],\n",
              "       [80., 29.],\n",
              "       [68., 94.],\n",
              "       [74., 33.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MFPbop0pOxh",
        "outputId": "de5d34fa-b60f-4ea1-9066-46403ead31c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "data_labels = (data[:,0] + data[:,1])[:,np.newaxis]\n",
        "data_labels[0:10,:]"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 82.],\n",
              "       [ 88.],\n",
              "       [ 41.],\n",
              "       [144.],\n",
              "       [ 31.],\n",
              "       [ 99.],\n",
              "       [149.],\n",
              "       [109.],\n",
              "       [162.],\n",
              "       [107.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvA_cusOu2oW"
      },
      "source": [
        "# Setup Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0FP7IDJu_Yy",
        "outputId": "10fd74db-5d8e-42a8-8afa-592970dbb9e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "statusNodes=1\n",
        "outputNodes=1\n",
        "feedbackNodes=5\n",
        "model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(2+feedbackNodes,)),\n",
        "    keras.layers.Dense(1000, activation='relu'),\n",
        "    keras.layers.Dense(statusNodes + outputNodes + feedbackNodes)\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 1000)              8000      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 7)                 7007      \n",
            "=================================================================\n",
            "Total params: 15,007\n",
            "Trainable params: 15,007\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFw_GfVR8i8n"
      },
      "source": [
        "# Setup Training\n",
        "Running equivalent of:\n",
        "```\n",
        "# fitres = model.fit(data, data_labels, validation_split=0.2, shuffle=True, epochs=150)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2h366BcfnHz"
      },
      "source": [
        "Trained to run with loop length 5, and asked to calculate 78 + 14, gives the following sub-results:\n",
        "```\n",
        "(tbd)\n",
        "```\n",
        "And the following final result:\n",
        "```\n",
        "(tbd)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJz4VsVZY8x",
        "outputId": "675a2bed-5398-4002-8708-359acd771cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "loss = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "a_true = tf.ones(shape=(5, 1))\n",
        "a_preds = tf.constant([\n",
        "                       [[0.0], [0.8], [0.9]],\n",
        "                       [[1.0], [1.1], [1.2]],\n",
        "                       [[2.0], [2.1], [2.2]],\n",
        "                       [[2.5], [0.1], [0.2]],\n",
        "                       [[0.5], [0.2], [0.4]]\n",
        "])\n",
        "\n",
        "#print(a_true)\n",
        "#print(a_preds)\n",
        "#loss(a_true, a_preds)\n",
        "#a_preds[0]\n",
        "#a_preds.shape\n",
        "\n",
        "#loss(a_true, a_preds[:,1,...])\n",
        "#loss(a_true, a_preds)\n",
        "\n",
        "print(f'a_preds.shape={a_preds.shape}')\n",
        "#tf.unstack(a_preds, axis=1)[0]\n",
        "l0 = loss(a_true, tf.unstack(a_preds, axis=1)[0])\n",
        "l1 = loss(a_true, tf.unstack(a_preds, axis=1)[1])\n",
        "print(l0)\n",
        "print(l1)\n",
        "#tf.stack([l0,l1],axis=1)\n",
        "#tf.stack([[i*2] for i in range(0,5)])\n",
        "#tf.map_fn(fn=lambda y_pred: loss(y_true, y_pred), elems=tf.unstack(a_preds, axis=1), fn_output_signature=tf.float32)\n",
        "\n",
        "losses = tf.stack([loss(y_true, y_pred) for y_pred in tf.unstack(a_preds, axis=1)], axis=1)\n",
        "print(f'losses.shape={losses.shape}')"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a_preds.shape=(5, 3, 1)\n",
            "tf.Tensor([1.   0.   1.   2.25 0.25], shape=(5,), dtype=float32)\n",
            "tf.Tensor([0.04       0.01       1.2099998  0.80999994 0.64000005], shape=(5,), dtype=float32)\n",
            "losses.shape=(5, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GaGNBoiTdy8",
        "outputId": "5bd5dcc7-5136-48d2-efe9-232ef1844ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "a_true = tf.ones(shape=(5, 1))\n",
        "a_preds = tf.constant([\n",
        "                       [[0.0, 0.0], [0.0, 0.8], [0.0, 0.9]],\n",
        "                       [[0.0, 1.0], [0.0, 1.1], [0.0, 1.2]],\n",
        "                       [[0.0, 2.2], [0.0, 2.1], [0.0, 2.3]],\n",
        "                       [[0.0, 2.5], [0.0, 0.1], [0.0, 0.2]],\n",
        "                       [[0.0, 0.5], [0.0, 0.2], [0.0, 0.4]]\n",
        "])\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def multiIterationLoss(y_true, y_preds):\n",
        "  \"\"\"Computes re-inforcement loss across loop execution.\n",
        "\n",
        "  Args:\n",
        "    y_true: Ground truth values.\n",
        "            Expected outcome, excluding status or feedback nodes.\n",
        "            shape = `(batch_size, output_nodes)`.\n",
        "    y_preds: The predicted values across all iterations of the loop.\n",
        "            Includes status, but excludes feedback nodes.\n",
        "            shape = `(batch_size, loop_size, status_nodes + output_nodes)`.\n",
        "\n",
        "  Returns:\n",
        "    Mean absolute squares values. shape = `(1)`.\n",
        "  \"\"\"\n",
        "\n",
        "  # REMEMBER: all operations are actioned ACROSS the whole batch\n",
        "\n",
        "  # Plan:\n",
        "  #  Loss Part A: must produce correct result it at least one iteration\n",
        "  #  Loss Part B: must yield >1.0 status against best result\n",
        "  #  Loss Part C: must NOT yield >1.0 status against wrong results\n",
        "\n",
        "  # Collect losses across batch and iterations\n",
        "  # maps: y_preds(bs, ls, sn+on) -> losses(bs, ls)    // ignoring status_nodes\n",
        "  # (note: mse is batch aware but configured to NOT sum across the batch,\n",
        "  #  so we'll need to manually do that sum at the end)\n",
        "  losses = tf.stack([\n",
        "                     mse(y_true, y_pred[:,1:, ...])\n",
        "                     for y_pred in tf.unstack(y_preds, axis=1)],\n",
        "                    axis=1)\n",
        "  print(f'losses across batch and iterations:\\n{losses}')\n",
        "\n",
        "  # Loss Part A: must produce correct result it at least one iteration\n",
        "  # (so take min loss across iterations)\n",
        "  #minLoss        = tf.min(losses, axis=1)\n",
        "  minLossIndices = tf.argmin(losses, axis=1)\n",
        "  minLoss        = tf.gather(losses, minLossIndices, batch_dims=1, axis=1)\n",
        "  print(f'min loss per-batch across iterations (indices {minLossIndices}):\\n{minLoss}')\n",
        "\n",
        "  batchLoss = tf.reduce_sum(minLoss)\n",
        "  print(f'batch loss: {batchLoss}')\n",
        "\n",
        "  # Loss Part A: must produce correct result it at least one iteration\n",
        "  #bestLoss = None\n",
        "  #bestI = None\n",
        "  #for i in range(y_preds.shape[0]):\n",
        "  #  y_pred = y_preds[i]\n",
        "  #  ls = loss(y_true, y_pred[1:, ...])\n",
        "  #  if bestLoss == None or ls < bestLoss:\n",
        "  #    bestLoss = ls\n",
        "  #    bestI = i\n",
        "  #print(f'best loss: {bestLoss} @ {bestI}')\n",
        "  \n",
        "  # Loss Part B: must yield >=1.0 status against best result\n",
        "  #statusLoss\n",
        "  #if y_preds[bestI][0] < 1.0\n",
        "  #  statusLoss = loss([10.0], y_preds[bestI][0])\n",
        "\n",
        "  # Loss Part C: must NOT yield >=1.0 status against wrong results\n",
        "\n",
        "  #return bestLoss\n",
        "  print('done.')\n",
        "  return batchLoss\n",
        "\n",
        "print(multiIterationLoss(a_true, a_preds))"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "losses across batch and iterations:\n",
            "[[1.         0.04       0.01      ]\n",
            " [0.         0.01       0.04000002]\n",
            " [1.44       1.2099998  1.6899998 ]\n",
            " [2.25       0.80999994 0.64000005]\n",
            " [0.25       0.64000005 0.36      ]]\n",
            "min loss per-batch across iterations (indices [2 0 1 2 0]):\n",
            "[0.01       0.         1.2099998  0.64000005 0.25      ]\n",
            "batch loss: 2.109999895095825\n",
            "done.\n",
            "tf.Tensor(2.11, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1X6bUtdwsiu"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "# Returns: y_preds - list of preds, where each y_pred is a tensor of shape = `(batch_size, d0, .. dN)`.\n",
        "@tf.function\n",
        "def compute(inputs, max_loop_length, training=False):\n",
        "  batchSize = inputs.shape[0]\n",
        "  outputs = []\n",
        "  feedback = tf.zeros(shape=(batchSize, feedbackNodes))\n",
        "\n",
        "  for i in range(max_loop_length):\n",
        "    # extend width of inputs with zeroed-out feedback\n",
        "    if i == 0:\n",
        "      inputsWithFeedback = tf.concat([inputs, feedback], axis=1)\n",
        "    else:\n",
        "      zeroedInputs = tf.zeros(shape=inputs.shape)\n",
        "      inputsWithFeedback = tf.concat([zeroedInputs, feedback], axis=1)\n",
        "  \n",
        "    # run model with inputs + feedback nodes\n",
        "    output = model(inputsWithFeedback, training)\n",
        "\n",
        "    # copy feedback for next iteration\n",
        "    feedback = output[:,-feedbackNodes:]\n",
        "\n",
        "    # produce output for records\n",
        "    # (note: doesn't use TF functions so don't re-use any of this for next iteration)\n",
        "    outputs.append(output[:,:-feedbackNodes])\n",
        "\n",
        "  return tf.stack(outputs, axis=1)\n",
        "\n",
        "# TODO\n",
        "def predict(inputs, max_loop_length, training=False):\n",
        "  # pick last iteration's output only and omit status nodes\n",
        "  return compute(inputs, max_loop_length, training)[:,-1,statusNodes:]\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, expected, max_loop_length):\n",
        "  with tf.GradientTape() as tape:\n",
        "    outputs = compute(inputs, max_loop_length, training=True)\n",
        "\n",
        "    # calculate loss ignoring feedback output\n",
        "    loop_loss = multiIterationLoss(expected, outputs)\n",
        "\n",
        "    # train model\n",
        "    gradients = tape.gradient(loop_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loop_loss"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK2xIQ3b_AIM"
      },
      "source": [
        "def fit(train_data, train_labels, epochs, batch_size, max_loop_length):\n",
        "  res = {}\n",
        "  res['loss'] = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print ('Epoch: {}/{}'.format(epoch+1, epochs))\n",
        "    start = time.time()\n",
        "    sum_loss = 0\n",
        "\n",
        "    # Train in batches\n",
        "    mx = (int(len(train_data)/batch_size))*batch_size\n",
        "    n  = mx/batch_size\n",
        "    print ('[', end='')\n",
        "    for i in range(0, mx, batch_size):\n",
        "      batch_data   = train_data[i:i+batch_size]\n",
        "      batch_labels = train_labels[i:i+batch_size]\n",
        "      sum_loss += train_step(batch_data, batch_labels, max_loop_length)\n",
        "      print ('=', end='')\n",
        "    print('] - {} sec - loss: {}'.format(time.time()-start, sum_loss/n))\n",
        "\n",
        "    # Record history\n",
        "    res['loss'].append(sum_loss/n)\n",
        "\n",
        "  return res"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJYYVtKz-6b-"
      },
      "source": [
        "# Run Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLkgvYqGB8wO",
        "outputId": "06025e16-a077-4719-fb8f-428376f51306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fitres = fit(data, data_labels, epochs=150, batch_size=32, max_loop_length=5)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/150\n",
            "[losses across batch and iterations:\n",
            "Tensor(\"stack:0\", shape=(32, 5), dtype=float32)\n",
            "min loss per-batch across iterations (indices Tensor(\"ArgMin:0\", shape=(32,), dtype=int64)):\n",
            "Tensor(\"GatherV2:0\", shape=(32,), dtype=float32)\n",
            "batch loss: Tensor(\"Sum:0\", shape=(), dtype=float32)\n",
            "done.\n",
            "losses across batch and iterations:\n",
            "Tensor(\"stack:0\", shape=(32, 5), dtype=float32)\n",
            "min loss per-batch across iterations (indices Tensor(\"ArgMin:0\", shape=(32,), dtype=int64)):\n",
            "Tensor(\"GatherV2:0\", shape=(32,), dtype=float32)\n",
            "batch loss: Tensor(\"Sum:0\", shape=(), dtype=float32)\n",
            "done.\n",
            "===============================] - 0.7227749824523926 sec - loss: 268901.78125\n",
            "Epoch: 2/150\n",
            "[===============================] - 0.0542604923248291 sec - loss: 157590.28125\n",
            "Epoch: 3/150\n",
            "[===============================] - 0.06244158744812012 sec - loss: 73985.5078125\n",
            "Epoch: 4/150\n",
            "[===============================] - 0.05834197998046875 sec - loss: 23932.28515625\n",
            "Epoch: 5/150\n",
            "[===============================] - 0.06067657470703125 sec - loss: 4549.458984375\n",
            "Epoch: 6/150\n",
            "[===============================] - 0.054404497146606445 sec - loss: 513.6839599609375\n",
            "Epoch: 7/150\n",
            "[===============================] - 0.05185985565185547 sec - loss: 62.542625427246094\n",
            "Epoch: 8/150\n",
            "[===============================] - 0.05687284469604492 sec - loss: 27.556230545043945\n",
            "Epoch: 9/150\n",
            "[===============================] - 0.053877830505371094 sec - loss: 22.334768295288086\n",
            "Epoch: 10/150\n",
            "[===============================] - 0.05201363563537598 sec - loss: 19.618114471435547\n",
            "Epoch: 11/150\n",
            "[===============================] - 0.052039146423339844 sec - loss: 17.738142013549805\n",
            "Epoch: 12/150\n",
            "[===============================] - 0.06256842613220215 sec - loss: 16.378524780273438\n",
            "Epoch: 13/150\n",
            "[===============================] - 0.05736589431762695 sec - loss: 15.353780746459961\n",
            "Epoch: 14/150\n",
            "[===============================] - 0.05429506301879883 sec - loss: 14.541571617126465\n",
            "Epoch: 15/150\n",
            "[===============================] - 0.05842328071594238 sec - loss: 13.862884521484375\n",
            "Epoch: 16/150\n",
            "[===============================] - 0.05385470390319824 sec - loss: 13.271081924438477\n",
            "Epoch: 17/150\n",
            "[===============================] - 0.05567741394042969 sec - loss: 12.737448692321777\n",
            "Epoch: 18/150\n",
            "[===============================] - 0.055089473724365234 sec - loss: 12.244904518127441\n",
            "Epoch: 19/150\n",
            "[===============================] - 0.05484437942504883 sec - loss: 11.783990859985352\n",
            "Epoch: 20/150\n",
            "[===============================] - 0.051724910736083984 sec - loss: 11.34987735748291\n",
            "Epoch: 21/150\n",
            "[===============================] - 0.052110910415649414 sec - loss: 10.938545227050781\n",
            "Epoch: 22/150\n",
            "[===============================] - 0.051055908203125 sec - loss: 10.54829216003418\n",
            "Epoch: 23/150\n",
            "[===============================] - 0.05911755561828613 sec - loss: 10.17803955078125\n",
            "Epoch: 24/150\n",
            "[===============================] - 0.05113697052001953 sec - loss: 9.825608253479004\n",
            "Epoch: 25/150\n",
            "[===============================] - 0.05192303657531738 sec - loss: 9.489566802978516\n",
            "Epoch: 26/150\n",
            "[===============================] - 0.05085635185241699 sec - loss: 9.166935920715332\n",
            "Epoch: 27/150\n",
            "[===============================] - 0.05357956886291504 sec - loss: 8.855639457702637\n",
            "Epoch: 28/150\n",
            "[===============================] - 0.05225515365600586 sec - loss: 8.547426223754883\n",
            "Epoch: 29/150\n",
            "[===============================] - 0.05477142333984375 sec - loss: 8.239477157592773\n",
            "Epoch: 30/150\n",
            "[===============================] - 0.05681109428405762 sec - loss: 7.933165550231934\n",
            "Epoch: 31/150\n",
            "[===============================] - 0.052780866622924805 sec - loss: 7.628877639770508\n",
            "Epoch: 32/150\n",
            "[===============================] - 0.06475186347961426 sec - loss: 7.331043720245361\n",
            "Epoch: 33/150\n",
            "[===============================] - 0.05647444725036621 sec - loss: 7.0460591316223145\n",
            "Epoch: 34/150\n",
            "[===============================] - 0.05458998680114746 sec - loss: 6.777360439300537\n",
            "Epoch: 35/150\n",
            "[===============================] - 0.0511629581451416 sec - loss: 6.527245998382568\n",
            "Epoch: 36/150\n",
            "[===============================] - 0.05733633041381836 sec - loss: 6.292867183685303\n",
            "Epoch: 37/150\n",
            "[===============================] - 0.0568082332611084 sec - loss: 6.074986457824707\n",
            "Epoch: 38/150\n",
            "[===============================] - 0.05191850662231445 sec - loss: 5.869004249572754\n",
            "Epoch: 39/150\n",
            "[===============================] - 0.053189992904663086 sec - loss: 5.674956321716309\n",
            "Epoch: 40/150\n",
            "[===============================] - 0.05309581756591797 sec - loss: 5.4894700050354\n",
            "Epoch: 41/150\n",
            "[===============================] - 0.0576319694519043 sec - loss: 5.312371730804443\n",
            "Epoch: 42/150\n",
            "[===============================] - 0.05045294761657715 sec - loss: 5.142570972442627\n",
            "Epoch: 43/150\n",
            "[===============================] - 0.054273366928100586 sec - loss: 4.979417324066162\n",
            "Epoch: 44/150\n",
            "[===============================] - 0.05244135856628418 sec - loss: 4.82293176651001\n",
            "Epoch: 45/150\n",
            "[===============================] - 0.05687260627746582 sec - loss: 4.67163610458374\n",
            "Epoch: 46/150\n",
            "[===============================] - 0.04983234405517578 sec - loss: 4.52562952041626\n",
            "Epoch: 47/150\n",
            "[===============================] - 0.05018496513366699 sec - loss: 4.385286331176758\n",
            "Epoch: 48/150\n",
            "[===============================] - 0.050459861755371094 sec - loss: 4.249846458435059\n",
            "Epoch: 49/150\n",
            "[===============================] - 0.052794694900512695 sec - loss: 4.119519233703613\n",
            "Epoch: 50/150\n",
            "[===============================] - 0.05005931854248047 sec - loss: 3.994025945663452\n",
            "Epoch: 51/150\n",
            "[===============================] - 0.05105304718017578 sec - loss: 3.8729991912841797\n",
            "Epoch: 52/150\n",
            "[===============================] - 0.05374264717102051 sec - loss: 3.75689959526062\n",
            "Epoch: 53/150\n",
            "[===============================] - 0.05472826957702637 sec - loss: 3.6451122760772705\n",
            "Epoch: 54/150\n",
            "[===============================] - 0.05272626876831055 sec - loss: 3.5375657081604004\n",
            "Epoch: 55/150\n",
            "[===============================] - 0.05394554138183594 sec - loss: 3.4339029788970947\n",
            "Epoch: 56/150\n",
            "[===============================] - 0.05076456069946289 sec - loss: 3.3341169357299805\n",
            "Epoch: 57/150\n",
            "[===============================] - 0.054175615310668945 sec - loss: 3.2375972270965576\n",
            "Epoch: 58/150\n",
            "[===============================] - 0.05052924156188965 sec - loss: 3.1445534229278564\n",
            "Epoch: 59/150\n",
            "[===============================] - 0.049832820892333984 sec - loss: 3.0548582077026367\n",
            "Epoch: 60/150\n",
            "[===============================] - 0.05706906318664551 sec - loss: 2.9684078693389893\n",
            "Epoch: 61/150\n",
            "[===============================] - 0.05537247657775879 sec - loss: 2.885023832321167\n",
            "Epoch: 62/150\n",
            "[===============================] - 0.04954695701599121 sec - loss: 2.804723024368286\n",
            "Epoch: 63/150\n",
            "[===============================] - 0.0510866641998291 sec - loss: 2.7277143001556396\n",
            "Epoch: 64/150\n",
            "[===============================] - 0.0542447566986084 sec - loss: 2.6536977291107178\n",
            "Epoch: 65/150\n",
            "[===============================] - 0.05147910118103027 sec - loss: 2.5826292037963867\n",
            "Epoch: 66/150\n",
            "[===============================] - 0.04988408088684082 sec - loss: 2.514221668243408\n",
            "Epoch: 67/150\n",
            "[===============================] - 0.05052661895751953 sec - loss: 2.448296546936035\n",
            "Epoch: 68/150\n",
            "[===============================] - 0.05255842208862305 sec - loss: 2.3848321437835693\n",
            "Epoch: 69/150\n",
            "[===============================] - 0.054299116134643555 sec - loss: 2.3236684799194336\n",
            "Epoch: 70/150\n",
            "[===============================] - 0.0491795539855957 sec - loss: 2.2647109031677246\n",
            "Epoch: 71/150\n",
            "[===============================] - 0.049704551696777344 sec - loss: 2.2079381942749023\n",
            "Epoch: 72/150\n",
            "[===============================] - 0.05335855484008789 sec - loss: 2.1531381607055664\n",
            "Epoch: 73/150\n",
            "[===============================] - 0.050109148025512695 sec - loss: 2.1002800464630127\n",
            "Epoch: 74/150\n",
            "[===============================] - 0.0508878231048584 sec - loss: 2.0491394996643066\n",
            "Epoch: 75/150\n",
            "[===============================] - 0.05069994926452637 sec - loss: 1.9997256994247437\n",
            "Epoch: 76/150\n",
            "[===============================] - 0.05318927764892578 sec - loss: 1.9518731832504272\n",
            "Epoch: 77/150\n",
            "[===============================] - 0.05079340934753418 sec - loss: 1.9058347940444946\n",
            "Epoch: 78/150\n",
            "[===============================] - 0.05009198188781738 sec - loss: 1.861170768737793\n",
            "Epoch: 79/150\n",
            "[===============================] - 0.05798506736755371 sec - loss: 1.8179869651794434\n",
            "Epoch: 80/150\n",
            "[===============================] - 0.05392765998840332 sec - loss: 1.7762037515640259\n",
            "Epoch: 81/150\n",
            "[===============================] - 0.05155444145202637 sec - loss: 1.7356544733047485\n",
            "Epoch: 82/150\n",
            "[===============================] - 0.05054211616516113 sec - loss: 1.6963510513305664\n",
            "Epoch: 83/150\n",
            "[===============================] - 0.05309796333312988 sec - loss: 1.658221960067749\n",
            "Epoch: 84/150\n",
            "[===============================] - 0.05593442916870117 sec - loss: 1.621159553527832\n",
            "Epoch: 85/150\n",
            "[===============================] - 0.05171990394592285 sec - loss: 1.5851088762283325\n",
            "Epoch: 86/150\n",
            "[===============================] - 0.052462100982666016 sec - loss: 1.550061821937561\n",
            "Epoch: 87/150\n",
            "[===============================] - 0.05240273475646973 sec - loss: 1.5159879922866821\n",
            "Epoch: 88/150\n",
            "[===============================] - 0.05445289611816406 sec - loss: 1.48284113407135\n",
            "Epoch: 89/150\n",
            "[===============================] - 0.053148508071899414 sec - loss: 1.4505928754806519\n",
            "Epoch: 90/150\n",
            "[===============================] - 0.05404496192932129 sec - loss: 1.4191237688064575\n",
            "Epoch: 91/150\n",
            "[===============================] - 0.05335736274719238 sec - loss: 1.3883593082427979\n",
            "Epoch: 92/150\n",
            "[===============================] - 0.052657365798950195 sec - loss: 1.3583933115005493\n",
            "Epoch: 93/150\n",
            "[===============================] - 0.051206350326538086 sec - loss: 1.3291007280349731\n",
            "Epoch: 94/150\n",
            "[===============================] - 0.049840688705444336 sec - loss: 1.300411343574524\n",
            "Epoch: 95/150\n",
            "[===============================] - 0.05425143241882324 sec - loss: 1.2723708152770996\n",
            "Epoch: 96/150\n",
            "[===============================] - 0.04946017265319824 sec - loss: 1.244925856590271\n",
            "Epoch: 97/150\n",
            "[===============================] - 0.05121922492980957 sec - loss: 1.2180368900299072\n",
            "Epoch: 98/150\n",
            "[===============================] - 0.05822634696960449 sec - loss: 1.1916583776474\n",
            "Epoch: 99/150\n",
            "[===============================] - 0.059738874435424805 sec - loss: 1.1657356023788452\n",
            "Epoch: 100/150\n",
            "[===============================] - 0.051369428634643555 sec - loss: 1.1402043104171753\n",
            "Epoch: 101/150\n",
            "[===============================] - 0.04913949966430664 sec - loss: 1.1152070760726929\n",
            "Epoch: 102/150\n",
            "[===============================] - 0.0493168830871582 sec - loss: 1.0905758142471313\n",
            "Epoch: 103/150\n",
            "[===============================] - 0.05684947967529297 sec - loss: 1.0663453340530396\n",
            "Epoch: 104/150\n",
            "[===============================] - 0.0624239444732666 sec - loss: 1.0424883365631104\n",
            "Epoch: 105/150\n",
            "[===============================] - 0.05167341232299805 sec - loss: 1.0190149545669556\n",
            "Epoch: 106/150\n",
            "[===============================] - 0.05536937713623047 sec - loss: 0.9958968162536621\n",
            "Epoch: 107/150\n",
            "[===============================] - 0.0519869327545166 sec - loss: 0.9730978608131409\n",
            "Epoch: 108/150\n",
            "[===============================] - 0.05051445960998535 sec - loss: 0.950590968132019\n",
            "Epoch: 109/150\n",
            "[===============================] - 0.05105948448181152 sec - loss: 0.928357720375061\n",
            "Epoch: 110/150\n",
            "[===============================] - 0.05309748649597168 sec - loss: 0.9064465165138245\n",
            "Epoch: 111/150\n",
            "[===============================] - 0.04965090751647949 sec - loss: 0.8848198652267456\n",
            "Epoch: 112/150\n",
            "[===============================] - 0.05106520652770996 sec - loss: 0.8634705543518066\n",
            "Epoch: 113/150\n",
            "[===============================] - 0.05011105537414551 sec - loss: 0.842466413974762\n",
            "Epoch: 114/150\n",
            "[===============================] - 0.051842689514160156 sec - loss: 0.8218094706535339\n",
            "Epoch: 115/150\n",
            "[===============================] - 0.050690650939941406 sec - loss: 0.8014585971832275\n",
            "Epoch: 116/150\n",
            "[===============================] - 0.0518035888671875 sec - loss: 0.781342625617981\n",
            "Epoch: 117/150\n",
            "[===============================] - 0.05541348457336426 sec - loss: 0.7615887522697449\n",
            "Epoch: 118/150\n",
            "[===============================] - 0.05448436737060547 sec - loss: 0.7420846223831177\n",
            "Epoch: 119/150\n",
            "[===============================] - 0.04897809028625488 sec - loss: 0.7228235006332397\n",
            "Epoch: 120/150\n",
            "[===============================] - 0.051114797592163086 sec - loss: 0.7037864327430725\n",
            "Epoch: 121/150\n",
            "[===============================] - 0.05100655555725098 sec - loss: 0.6849798560142517\n",
            "Epoch: 122/150\n",
            "[===============================] - 0.05346059799194336 sec - loss: 0.6663898825645447\n",
            "Epoch: 123/150\n",
            "[===============================] - 0.053552865982055664 sec - loss: 0.6480941772460938\n",
            "Epoch: 124/150\n",
            "[===============================] - 0.05942559242248535 sec - loss: 0.6300641298294067\n",
            "Epoch: 125/150\n",
            "[===============================] - 0.05127763748168945 sec - loss: 0.6122069954872131\n",
            "Epoch: 126/150\n",
            "[===============================] - 0.05350947380065918 sec - loss: 0.5947186350822449\n",
            "Epoch: 127/150\n",
            "[===============================] - 0.049044132232666016 sec - loss: 0.5775269269943237\n",
            "Epoch: 128/150\n",
            "[===============================] - 0.058647871017456055 sec - loss: 0.5606678128242493\n",
            "Epoch: 129/150\n",
            "[===============================] - 0.06575417518615723 sec - loss: 0.5441188812255859\n",
            "Epoch: 130/150\n",
            "[===============================] - 0.06035256385803223 sec - loss: 0.5278568267822266\n",
            "Epoch: 131/150\n",
            "[===============================] - 0.052641868591308594 sec - loss: 0.5118783712387085\n",
            "Epoch: 132/150\n",
            "[===============================] - 0.04909467697143555 sec - loss: 0.4962576627731323\n",
            "Epoch: 133/150\n",
            "[===============================] - 0.051599740982055664 sec - loss: 0.48085519671440125\n",
            "Epoch: 134/150\n",
            "[===============================] - 0.04985380172729492 sec - loss: 0.465719610452652\n",
            "Epoch: 135/150\n",
            "[===============================] - 0.056085824966430664 sec - loss: 0.4508161246776581\n",
            "Epoch: 136/150\n",
            "[===============================] - 0.06930136680603027 sec - loss: 0.43621471524238586\n",
            "Epoch: 137/150\n",
            "[===============================] - 0.05399274826049805 sec - loss: 0.4218902289867401\n",
            "Epoch: 138/150\n",
            "[===============================] - 0.05048513412475586 sec - loss: 0.4078630208969116\n",
            "Epoch: 139/150\n",
            "[===============================] - 0.05037498474121094 sec - loss: 0.3941211700439453\n",
            "Epoch: 140/150\n",
            "[===============================] - 0.055202484130859375 sec - loss: 0.38068053126335144\n",
            "Epoch: 141/150\n",
            "[===============================] - 0.04998278617858887 sec - loss: 0.3675118386745453\n",
            "Epoch: 142/150\n",
            "[===============================] - 0.04949450492858887 sec - loss: 0.3546367287635803\n",
            "Epoch: 143/150\n",
            "[===============================] - 0.0505213737487793 sec - loss: 0.34205374121665955\n",
            "Epoch: 144/150\n",
            "[===============================] - 0.052968502044677734 sec - loss: 0.3297536075115204\n",
            "Epoch: 145/150\n",
            "[===============================] - 0.0527951717376709 sec - loss: 0.3177490830421448\n",
            "Epoch: 146/150\n",
            "[===============================] - 0.05448555946350098 sec - loss: 0.3060203194618225\n",
            "Epoch: 147/150\n",
            "[===============================] - 0.05033683776855469 sec - loss: 0.29457929730415344\n",
            "Epoch: 148/150\n",
            "[===============================] - 0.0536952018737793 sec - loss: 0.28339868783950806\n",
            "Epoch: 149/150\n",
            "[===============================] - 0.05410361289978027 sec - loss: 0.2725048363208771\n",
            "Epoch: 150/150\n",
            "[===============================] - 0.048989057540893555 sec - loss: 0.2618870437145233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqJMre6D-4TJ"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiR1k19dzyak",
        "outputId": "a3b0fa2f-0141-4f0b-9607-e70b3331b595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(['x', 'y', 'expected', 'actual'])\n",
        "print(np.concatenate((data[800:810], data_labels[800:810], predict(data[800:810], 5)), axis=1))"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['x', 'y', 'expected', 'actual']\n",
            "[[3.30000000e+01 6.80000000e+01 1.01000000e+02 1.23463243e-01]\n",
            " [1.70000000e+01 1.30000000e+01 3.00000000e+01 1.23833977e-01]\n",
            " [3.50000000e+01 9.60000000e+01 1.31000000e+02 1.23275906e-01]\n",
            " [3.60000000e+01 6.20000000e+01 9.80000000e+01 1.23423450e-01]\n",
            " [6.50000000e+01 2.60000000e+01 9.10000000e+01 1.23305783e-01]\n",
            " [5.70000000e+01 8.70000000e+01 1.44000000e+02 1.22991778e-01]\n",
            " [7.80000000e+01 7.70000000e+01 1.55000000e+02 1.22749247e-01]\n",
            " [7.00000000e+00 8.50000000e+01 9.20000000e+01 1.23465419e-01]\n",
            " [4.50000000e+01 3.30000000e+01 7.80000000e+01 1.23418018e-01]\n",
            " [3.40000000e+01 8.40000000e+01 1.18000000e+02 1.23373792e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wHPRONEGV-L",
        "outputId": "536a04cb-cd6e-4a14-8087-9f4b9ea3f7b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.semilogy(fitres['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1DFcorH4_-1"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x4yhkHx5EOx",
        "outputId": "5c9072fb-b9f8-4256-cc10-a8e8b0057d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(compute(data[800:810], 6))"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[-8.11963081e-02  1.01008568e+02]\n",
            "  [ 9.13317323e-01  5.22997332e+00]\n",
            "  [-5.82686365e-02  2.67587692e-01]\n",
            "  [ 9.21471044e-04  1.25225425e-01]\n",
            "  [-1.55253452e-03  1.23463243e-01]\n",
            "  [ 3.25103756e-05  1.24129191e-01]]\n",
            "\n",
            " [[-6.71187639e-01  3.02151031e+01]\n",
            "  [ 2.64416933e-01  1.41335523e+00]\n",
            "  [-2.32463069e-02  1.39013276e-01]\n",
            "  [ 4.93781525e-04  1.24041200e-01]\n",
            "  [-6.26108900e-04  1.23833977e-01]\n",
            "  [ 2.73562036e-05  1.24127410e-01]]\n",
            "\n",
            " [[ 7.14787006e-01  1.30956497e+02]\n",
            "  [ 1.22873282e+00  6.94231653e+00]\n",
            "  [-6.86744228e-02  3.35029215e-01]\n",
            "  [ 1.14291534e-03  1.28138289e-01]\n",
            "  [-1.90740603e-03  1.23275906e-01]\n",
            "  [ 4.23414167e-05  1.24130324e-01]]\n",
            "\n",
            " [[-4.33419466e-01  9.80281067e+01]\n",
            "  [ 8.78434062e-01  4.97749138e+00]\n",
            "  [-5.96974865e-02  2.65652359e-01]\n",
            "  [ 1.23419159e-03  1.25565350e-01]\n",
            "  [-1.58069946e-03  1.23423450e-01]\n",
            "  [ 3.05871945e-05  1.24126852e-01]]\n",
            "\n",
            " [[-3.17474461e+00  9.10611420e+01]\n",
            "  [ 7.54891336e-01  3.94654799e+00]\n",
            "  [-8.32300484e-02  3.14152092e-01]\n",
            "  [ 2.93399394e-03  1.27809852e-01]\n",
            "  [-1.59317162e-03  1.23305783e-01]\n",
            "  [ 2.35770131e-05  1.24118246e-01]]\n",
            "\n",
            " [[-9.86761808e-01  1.43979965e+02]\n",
            "  [ 1.28682542e+00  7.15244913e+00]\n",
            "  [-9.01401639e-02  3.78821909e-01]\n",
            "  [ 4.20458429e-03  1.33701518e-01]\n",
            "  [-2.33985391e-03  1.22991778e-01]\n",
            "  [ 4.01966390e-05  1.24123566e-01]]\n",
            "\n",
            " [[-2.49571848e+00  1.54991043e+02]\n",
            "  [ 1.38994420e+00  7.25634050e+00]\n",
            "  [-1.10362947e-01  4.29972172e-01]\n",
            "  [ 6.28962927e-03  1.39862210e-01]\n",
            "  [-2.66017346e-03  1.22749247e-01]\n",
            "  [ 3.37842503e-05  1.24119520e-01]]\n",
            "\n",
            " [[ 2.24893284e+00  9.19453583e+01]\n",
            "  [ 1.01741111e+00  5.32523489e+00]\n",
            "  [-4.83784080e-02  2.83920944e-01]\n",
            "  [ 4.63812263e-04  1.25813514e-01]\n",
            "  [-1.56996993e-03  1.23465419e-01]\n",
            "  [ 4.30329237e-05  1.24134287e-01]]\n",
            "\n",
            " [[-1.80417669e+00  7.81423264e+01]\n",
            "  [ 6.80172086e-01  3.54370046e+00]\n",
            "  [-6.15934208e-02  2.48621106e-01]\n",
            "  [ 2.37056497e-03  1.25997588e-01]\n",
            "  [-1.44405081e-03  1.23418018e-01]\n",
            "  [ 3.04619898e-05  1.24124572e-01]]\n",
            "\n",
            " [[ 3.81918192e-01  1.17989220e+02]\n",
            "  [ 1.09027648e+00  6.20426416e+00]\n",
            "  [-6.37502447e-02  3.04097265e-01]\n",
            "  [ 9.33311880e-04  1.26549572e-01]\n",
            "  [-1.73590297e-03  1.23373792e-01]\n",
            "  [ 3.74935917e-05  1.24130026e-01]]], shape=(10, 6, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_1NCm-uCktQ",
        "outputId": "9ae12782-1d7c-4aa7-a089-6ec6c69816a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "predict(data[800:810], 6)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[0.12412919],\n",
              "       [0.12412741],\n",
              "       [0.12413032],\n",
              "       [0.12412685],\n",
              "       [0.12411825],\n",
              "       [0.12412357],\n",
              "       [0.12411952],\n",
              "       [0.12413429],\n",
              "       [0.12412457],\n",
              "       [0.12413003]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    }
  ]
}