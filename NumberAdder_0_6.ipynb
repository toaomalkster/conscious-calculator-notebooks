{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NumberAdder-0.6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMduqU8i8utaL9x+aZ92L7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toaomalkster/conscious-calculator-notebooks/blob/main/NumberAdder_0_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7LX96lpBYkT"
      },
      "source": [
        "# Number Adder\n",
        "0.6:\n",
        "* Extension of capabilities to force more interesting usage of the loop capability:\n",
        "   * Extra input node/s to indicate which operation to apply.\n",
        "   * Some operations will be more efficiently done by using one loop iteration to compute an intermediate result. So should see that used loop length will vary depending on operation.\n",
        "   * Note that some of these operations will require a deeper network.\n",
        "* Some operations to consider:\n",
        "   * 'equal' - just passes 'a' input as output\n",
        "   * 'sum'\n",
        "   * 'add and double'\n",
        "   * 'sum of add and multiply' - a+b + a*b\n",
        "\n",
        "## Background\n",
        "Building up towards a model based on Consciousness V2 theory.\n",
        "\n",
        "## Loss Function Considerations\n",
        "Non-negotiables:\n",
        "* Must produce the correct result at some point\n",
        "* Must not falsely represent the result -- ie: if there is a 'completion' flag, then it must always be close to zero if not outputting the result\n",
        "\n",
        "Fuzzy requirements:\n",
        "* Accuracy is more important than efficiency\n",
        "* Needs to identify 'completion' somehow\n",
        "\n",
        "Ideal optimisation requirements:\n",
        "* Minimise effort to produce result\n",
        "  * Optimises for quicker response times\n",
        "  * Also a protection against infinite loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YL5HKtzQRHWg"
      },
      "source": [
        "**App Boilerplate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ruY3TtqP1gb",
        "outputId": "d39038ff-54ff-4fea-87b5-240a3650cbc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuRO0frKRXNG"
      },
      "source": [
        "# Setup Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9uKG-DgmzBj",
        "outputId": "5762f2a4-0d42-4e38-b33f-34922fd157ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "data = np.random.randint(100, size=(1000, 2)).astype('float32')\n",
        "data[0:10,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5., 77.],\n",
              "       [ 1., 87.],\n",
              "       [41.,  0.],\n",
              "       [62., 82.],\n",
              "       [15., 16.],\n",
              "       [96.,  3.],\n",
              "       [56., 93.],\n",
              "       [80., 29.],\n",
              "       [68., 94.],\n",
              "       [74., 33.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MFPbop0pOxh",
        "outputId": "de5d34fa-b60f-4ea1-9066-46403ead31c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "data_labels = (data[:,0] + data[:,1])[:,np.newaxis]\n",
        "data_labels[0:10,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 82.],\n",
              "       [ 88.],\n",
              "       [ 41.],\n",
              "       [144.],\n",
              "       [ 31.],\n",
              "       [ 99.],\n",
              "       [149.],\n",
              "       [109.],\n",
              "       [162.],\n",
              "       [107.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvA_cusOu2oW"
      },
      "source": [
        "# Setup Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0FP7IDJu_Yy",
        "outputId": "17eeb701-0620-42f0-82da-fd9f8296f86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "statusNodes=1\n",
        "outputNodes=1\n",
        "feedbackNodes=5\n",
        "model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(2+feedbackNodes,)),\n",
        "    keras.layers.Dense(1000, activation='relu'),\n",
        "    keras.layers.Dense(statusNodes + outputNodes + feedbackNodes)\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 1000)              8000      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 7)                 7007      \n",
            "=================================================================\n",
            "Total params: 15,007\n",
            "Trainable params: 15,007\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFw_GfVR8i8n"
      },
      "source": [
        "# Setup Training\n",
        "Running equivalent of:\n",
        "```\n",
        "# fitres = model.fit(data, data_labels, validation_split=0.2, shuffle=True, epochs=150)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2h366BcfnHz"
      },
      "source": [
        "Trained to run with loop length 5, and asked to calculate 78 + 14, gives the following sub-results:\n",
        "```\n",
        "(tbd)\n",
        "```\n",
        "And the following final result:\n",
        "```\n",
        "(tbd)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPJz4VsVZY8x",
        "outputId": "675a2bed-5398-4002-8708-359acd771cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "loss = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "a_true = tf.ones(shape=(5, 1))\n",
        "a_preds = tf.constant([\n",
        "                       [[0.0], [0.8], [0.9]],\n",
        "                       [[1.0], [1.1], [1.2]],\n",
        "                       [[2.0], [2.1], [2.2]],\n",
        "                       [[2.5], [0.1], [0.2]],\n",
        "                       [[0.5], [0.2], [0.4]]\n",
        "])\n",
        "\n",
        "#print(a_true)\n",
        "#print(a_preds)\n",
        "#loss(a_true, a_preds)\n",
        "#a_preds[0]\n",
        "#a_preds.shape\n",
        "\n",
        "#loss(a_true, a_preds[:,1,...])\n",
        "#loss(a_true, a_preds)\n",
        "\n",
        "print(f'a_preds.shape={a_preds.shape}')\n",
        "#tf.unstack(a_preds, axis=1)[0]\n",
        "l0 = loss(a_true, tf.unstack(a_preds, axis=1)[0])\n",
        "l1 = loss(a_true, tf.unstack(a_preds, axis=1)[1])\n",
        "print(l0)\n",
        "print(l1)\n",
        "#tf.stack([l0,l1],axis=1)\n",
        "#tf.stack([[i*2] for i in range(0,5)])\n",
        "#tf.map_fn(fn=lambda y_pred: loss(y_true, y_pred), elems=tf.unstack(a_preds, axis=1), fn_output_signature=tf.float32)\n",
        "\n",
        "losses = tf.stack([loss(y_true, y_pred) for y_pred in tf.unstack(a_preds, axis=1)], axis=1)\n",
        "print(f'losses.shape={losses.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a_preds.shape=(5, 3, 1)\n",
            "tf.Tensor([1.   0.   1.   2.25 0.25], shape=(5,), dtype=float32)\n",
            "tf.Tensor([0.04       0.01       1.2099998  0.80999994 0.64000005], shape=(5,), dtype=float32)\n",
            "losses.shape=(5, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTUog0hdJHmN",
        "outputId": "7fba5acc-5174-4220-e505-f0f06e72f08d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# statuses\n",
        "mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "a_true = tf.one_hot([2, 2, 1, 2, 0], 3, on_value=10.0, off_value=0.0)\n",
        "a_preds = tf.constant([\n",
        "                       [[0.0, 0.0], [1.0, 0.8], [3.0, 0.9]],\n",
        "                       [[0.0, 1.0], [1.0, 1.1], [3.0, 1.2]],\n",
        "                       [[0.0, 2.2], [1.0, 2.1], [3.0, 2.3]],\n",
        "                       [[0.0, 2.5], [1.0, 0.1], [3.0, 0.2]],\n",
        "                       [[0.0, 0.5], [1.0, 0.2], [3.0, 0.4]]\n",
        "])\n",
        "\n",
        "#tf.unstack(a_preds, axis=1)[0]\n",
        "print(f'true:\\n{a_true}')\n",
        "print(f'preds:\\n{a_preds[:,:,0]}')\n",
        "mse(a_true, a_preds[:,:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "true:\n",
            "[[ 0.  0. 10.]\n",
            " [ 0.  0. 10.]\n",
            " [ 0. 10.  0.]\n",
            " [ 0.  0. 10.]\n",
            " [10.  0.  0.]]\n",
            "preds:\n",
            "[[0. 1. 3.]\n",
            " [0. 1. 3.]\n",
            " [0. 1. 3.]\n",
            " [0. 1. 3.]\n",
            " [0. 1. 3.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
              "array([16.666666, 16.666666, 30.      , 16.666666, 36.666668],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjMzqlKGN7DP",
        "outputId": "1b766ce4-c7a6-4286-8e03-7362ff4b75be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# selecting from statuses\n",
        "a_preds = tf.constant([\n",
        "                       [[0.0, 0.0], [1.0, 0.8], [3.0, 0.9]],\n",
        "                       [[0.0, 1.0], [1.0, 1.1], [3.0, 1.2]],\n",
        "                       [[0.0, 2.2], [1.0, 2.1], [3.0, 2.3]],\n",
        "                       [[0.0, 2.5], [1.0, 0.1], [3.0, 0.2]],\n",
        "                       [[0.0, 0.5], [1.0, 0.2], [3.0, 0.4]]\n",
        "])\n",
        "b = tf.unstack(a_preds, axis=0)[0]\n",
        "print(f'b: {b}')\n",
        "\n",
        "tf.stack([tf.argmax(tf.map_fn(fn=lambda t: 0 if t[0] < 1.0 else 1.0, elems=b)) for b in tf.unstack(a_preds, axis=0)], axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b: [[0.  0. ]\n",
            " [1.  0.8]\n",
            " [3.  0.9]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 1, 1, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GaGNBoiTdy8",
        "outputId": "7021dc7f-dd6a-4329-86cb-763de81edeee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "a_true = tf.ones(shape=(5, 1))\n",
        "a_preds = tf.constant([\n",
        "                       [[0.0, 0.0], [1.0, 0.8], [3.0, 0.9]],\n",
        "                       [[0.0, 1.0], [1.0, 1.1], [3.0, 1.2]],\n",
        "                       [[0.0, 2.2], [1.0, 2.1], [3.0, 2.3]],\n",
        "                       [[0.0, 2.5], [1.0, 0.1], [3.0, 0.2]],\n",
        "                       [[0.0, 0.5], [1.0, 0.2], [3.0, 0.4]]\n",
        "])\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def multiIterationLoss(y_true, y_preds):\n",
        "  \"\"\"Computes re-inforcement loss across loop execution.\n",
        "\n",
        "  Args:\n",
        "    y_true: Ground truth values.\n",
        "            Expected outcome, excluding status or feedback nodes.\n",
        "            shape = `(batch_size, output_nodes)`.\n",
        "    y_preds: The predicted values across all iterations of the loop.\n",
        "            Includes status, but excludes feedback nodes.\n",
        "            shape = `(batch_size, loop_size, status_nodes + output_nodes)`.\n",
        "\n",
        "  Returns:\n",
        "    Mean absolute squares values. shape = `(1)`.\n",
        "  \"\"\"\n",
        "\n",
        "  # REMEMBER: all operations are actioned ACROSS the whole batch\n",
        "\n",
        "  # Plan:\n",
        "  #  Loss Part A: must produce correct result it at least one iteration\n",
        "  #  Loss Part B: must yield >1.0 status against best result\n",
        "  #  Loss Part C: must NOT yield >1.0 status against wrong results\n",
        "  iterationCount = y_preds.shape[1]\n",
        "\n",
        "  # Collect losses across batch and iterations\n",
        "  # maps: y_preds(bs, ls, sn+on) -> losses(bs, ls)    // ignoring status_nodes\n",
        "  # (note: mse is batch aware but configured to NOT sum across the batch,\n",
        "  #  so we'll need to manually do that sum at the end)\n",
        "  losses = tf.stack([\n",
        "                     mse(y_true, y_pred[:,1:, ...])\n",
        "                     for y_pred in tf.unstack(y_preds, axis=1)],\n",
        "                    axis=1)\n",
        "  print(f'output losses across batch and iterations:\\n{losses}')\n",
        "\n",
        "  # Loss Part A: must produce correct result it at least one iteration\n",
        "  # (so take min loss across iterations)\n",
        "  # (note: argmin biases towards earlier indices if there are duplicates)\n",
        "  minLossIndices = tf.argmin(losses, axis=1)\n",
        "  minLoss        = tf.gather(losses, minLossIndices, batch_dims=1, axis=1)\n",
        "  print(f'min output loss per-batch (indices {minLossIndices}):\\n{minLoss}')\n",
        "\n",
        "  # Loss Part B: must yield >=1.0 status against best result\n",
        "  # Loss Part C: must NOT yield >=1.0 status against wrong results\n",
        "  status_true = tf.one_hot(minLossIndices, iterationCount, on_value=10.0, off_value=0.0)\n",
        "  print(f'status: {status_true}')\n",
        "  statusLoss = mse(status_true, y_preds[:,:,0])\n",
        "  print(f'status losses per-batch: \\n{statusLoss}')\n",
        "\n",
        "  # combine losses\n",
        "  batchLoss = tf.reduce_sum([tf.reduce_sum(minLoss), tf.reduce_sum(statusLoss)])\n",
        "  print(f'batch output loss: {tf.reduce_sum(minLoss)}')\n",
        "  print(f'batch status loss: {tf.reduce_sum(statusLoss)}')\n",
        "  print(f'batch loss:        {batchLoss}')\n",
        "  return batchLoss\n",
        "\n",
        "print(multiIterationLoss(a_true, a_preds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output losses across batch and iterations:\n",
            "[[1.         0.04       0.01      ]\n",
            " [0.         0.01       0.04000002]\n",
            " [1.44       1.2099998  1.6899998 ]\n",
            " [2.25       0.80999994 0.64000005]\n",
            " [0.25       0.64000005 0.36      ]]\n",
            "min output loss per-batch (indices [2 0 1 2 0]):\n",
            "[0.01       0.         1.2099998  0.64000005 0.25      ]\n",
            "status: [[ 0.  0. 10.]\n",
            " [10.  0.  0.]\n",
            " [ 0. 10.  0.]\n",
            " [ 0.  0. 10.]\n",
            " [10.  0.  0.]]\n",
            "status losses per-batch: \n",
            "[16.666666 36.666668 30.       16.666666 36.666668]\n",
            "batch output loss: 2.109999895095825\n",
            "batch status loss: 136.6666717529297\n",
            "batch loss:        138.77667236328125\n",
            "tf.Tensor(138.77667, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1X6bUtdwsiu"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "# Returns: y_preds - list of preds, where each y_pred is a tensor of shape = `(batch_size, d0, .. dN)`.\n",
        "@tf.function\n",
        "def compute(inputs, max_loop_length, training=False):\n",
        "  batchSize = inputs.shape[0]\n",
        "  outputs = []\n",
        "  feedback = tf.zeros(shape=(batchSize, feedbackNodes))\n",
        "\n",
        "  for i in range(max_loop_length):\n",
        "    # extend width of inputs with zeroed-out feedback\n",
        "    if i == 0:\n",
        "      inputsWithFeedback = tf.concat([inputs, feedback], axis=1)\n",
        "    else:\n",
        "      zeroedInputs = tf.zeros(shape=inputs.shape)\n",
        "      inputsWithFeedback = tf.concat([zeroedInputs, feedback], axis=1)\n",
        "  \n",
        "    # run model with inputs + feedback nodes\n",
        "    output = model(inputsWithFeedback, training)\n",
        "\n",
        "    # copy feedback for next iteration\n",
        "    feedback = output[:,-feedbackNodes:]\n",
        "\n",
        "    # produce output for records\n",
        "    # (note: doesn't use TF functions so don't re-use any of this for next iteration)\n",
        "    outputs.append(output[:,:-feedbackNodes])\n",
        "\n",
        "  return tf.stack(outputs, axis=1)\n",
        "\n",
        "# Picks first where statusNode >=1.0; otherwise returns None\n",
        "def predict(inputs, max_loop_length, training=False):\n",
        "  # pick last iteration's output only and omit status nodes\n",
        "  outputs = compute(inputs, max_loop_length, training)\n",
        "\n",
        "  preds = []\n",
        "  for b in tf.unstack(outputs, axis=0):\n",
        "    #print(f'batch:\\n{b}')\n",
        "    statuses = tf.map_fn(fn=lambda t: 0 if t[0] < 1.0 else 10.0, elems=b)\n",
        "    if tf.reduce_max(statuses) > 1.0:\n",
        "      index = tf.argmax(statuses)\n",
        "      preds.append(b[index,1:])\n",
        "      #print(f' result: max={tf.reduce_max(statuses)}, index={tf.argmax(statuses)} -> append: {b[index,1:]}')\n",
        "    else:\n",
        "      preds.append(None)\n",
        "      #print(f' result: max={tf.reduce_max(statuses)}')\n",
        "  return tf.stack(preds, axis=0)\n",
        "\n",
        "@tf.function\n",
        "def train_step(inputs, expected, max_loop_length):\n",
        "  with tf.GradientTape() as tape:\n",
        "    outputs = compute(inputs, max_loop_length, training=True)\n",
        "\n",
        "    # calculate loss ignoring feedback output\n",
        "    loop_loss = multiIterationLoss(expected, outputs)\n",
        "\n",
        "    # train model\n",
        "    gradients = tape.gradient(loop_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loop_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK2xIQ3b_AIM"
      },
      "source": [
        "def fit(train_data, train_labels, epochs, batch_size, max_loop_length):\n",
        "  res = {}\n",
        "  res['loss'] = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    print ('Epoch: {}/{}'.format(epoch+1, epochs))\n",
        "    start = time.time()\n",
        "    sum_loss = 0\n",
        "\n",
        "    # Train in batches\n",
        "    mx = (int(len(train_data)/batch_size))*batch_size\n",
        "    n  = mx/batch_size\n",
        "    print ('[', end='')\n",
        "    for i in range(0, mx, batch_size):\n",
        "      batch_data   = train_data[i:i+batch_size]\n",
        "      batch_labels = train_labels[i:i+batch_size]\n",
        "      sum_loss += train_step(batch_data, batch_labels, max_loop_length)\n",
        "      print ('=', end='')\n",
        "    print('] - {} sec - loss: {}'.format(time.time()-start, sum_loss/n))\n",
        "\n",
        "    # Record history\n",
        "    res['loss'].append(sum_loss/n)\n",
        "\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJYYVtKz-6b-"
      },
      "source": [
        "# Run Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLkgvYqGB8wO",
        "outputId": "6831b690-6fbc-4d15-a33a-d2b1410b36f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fitres = fit(data, data_labels, epochs=1000, batch_size=32, max_loop_length=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/1000\n",
            "[output losses across batch and iterations:\n",
            "Tensor(\"stack:0\", shape=(32, 5), dtype=float32)\n",
            "min output loss per-batch (indices Tensor(\"ArgMin:0\", shape=(32,), dtype=int64)):\n",
            "Tensor(\"GatherV2:0\", shape=(32,), dtype=float32)\n",
            "status: Tensor(\"one_hot:0\", shape=(32, 5), dtype=float32)\n",
            "status losses per-batch: \n",
            "Tensor(\"mean_squared_error_5/weighted_loss/Mul:0\", shape=(32,), dtype=float32)\n",
            "batch output loss: Tensor(\"Sum_3:0\", shape=(), dtype=float32)\n",
            "batch status loss: Tensor(\"Sum_4:0\", shape=(), dtype=float32)\n",
            "batch loss:        Tensor(\"Sum_2:0\", shape=(), dtype=float32)\n",
            "output losses across batch and iterations:\n",
            "Tensor(\"stack:0\", shape=(32, 5), dtype=float32)\n",
            "min output loss per-batch (indices Tensor(\"ArgMin:0\", shape=(32,), dtype=int64)):\n",
            "Tensor(\"GatherV2:0\", shape=(32,), dtype=float32)\n",
            "status: Tensor(\"one_hot:0\", shape=(32, 5), dtype=float32)\n",
            "status losses per-batch: \n",
            "Tensor(\"mean_squared_error_5/weighted_loss/Mul:0\", shape=(32,), dtype=float32)\n",
            "batch output loss: Tensor(\"Sum_3:0\", shape=(), dtype=float32)\n",
            "batch status loss: Tensor(\"Sum_4:0\", shape=(), dtype=float32)\n",
            "batch loss:        Tensor(\"Sum_2:0\", shape=(), dtype=float32)\n",
            "===============================] - 0.8432736396789551 sec - loss: 295303.34375\n",
            "Epoch: 2/1000\n",
            "[===============================] - 0.05269265174865723 sec - loss: 175789.84375\n",
            "Epoch: 3/1000\n",
            "[===============================] - 0.0567469596862793 sec - loss: 85443.640625\n",
            "Epoch: 4/1000\n",
            "[===============================] - 0.05252408981323242 sec - loss: 29742.4453125\n",
            "Epoch: 5/1000\n",
            "[===============================] - 0.04924654960632324 sec - loss: 6851.29541015625\n",
            "Epoch: 6/1000\n",
            "[===============================] - 0.04950141906738281 sec - loss: 1244.6658935546875\n",
            "Epoch: 7/1000\n",
            "[===============================] - 0.05066728591918945 sec - loss: 369.68035888671875\n",
            "Epoch: 8/1000\n",
            "[===============================] - 0.06448221206665039 sec - loss: 232.94793701171875\n",
            "Epoch: 9/1000\n",
            "[===============================] - 0.05874991416931152 sec - loss: 182.6013641357422\n",
            "Epoch: 10/1000\n",
            "[===============================] - 0.052181243896484375 sec - loss: 150.67034912109375\n",
            "Epoch: 11/1000\n",
            "[===============================] - 0.04893064498901367 sec - loss: 129.1162872314453\n",
            "Epoch: 12/1000\n",
            "[===============================] - 0.052059173583984375 sec - loss: 114.80492401123047\n",
            "Epoch: 13/1000\n",
            "[===============================] - 0.0516812801361084 sec - loss: 105.49411010742188\n",
            "Epoch: 14/1000\n",
            "[===============================] - 0.05376267433166504 sec - loss: 99.5202865600586\n",
            "Epoch: 15/1000\n",
            "[===============================] - 0.05573010444641113 sec - loss: 95.70439147949219\n",
            "Epoch: 16/1000\n",
            "[===============================] - 0.05918169021606445 sec - loss: 93.24639129638672\n",
            "Epoch: 17/1000\n",
            "[===============================] - 0.04857492446899414 sec - loss: 91.62187957763672\n",
            "Epoch: 18/1000\n",
            "[===============================] - 0.04966235160827637 sec - loss: 90.49662017822266\n",
            "Epoch: 19/1000\n",
            "[===============================] - 0.049169063568115234 sec - loss: 89.66668701171875\n",
            "Epoch: 20/1000\n",
            "[===============================] - 0.05059099197387695 sec - loss: 89.00875854492188\n",
            "Epoch: 21/1000\n",
            "[===============================] - 0.0496976375579834 sec - loss: 88.44470977783203\n",
            "Epoch: 22/1000\n",
            "[===============================] - 0.049399375915527344 sec - loss: 87.45829010009766\n",
            "Epoch: 23/1000\n",
            "[===============================] - 0.057399749755859375 sec - loss: 86.53378295898438\n",
            "Epoch: 24/1000\n",
            "[===============================] - 0.05061674118041992 sec - loss: 85.73587036132812\n",
            "Epoch: 25/1000\n",
            "[===============================] - 0.04967808723449707 sec - loss: 85.00676727294922\n",
            "Epoch: 26/1000\n",
            "[===============================] - 0.048993825912475586 sec - loss: 84.33342742919922\n",
            "Epoch: 27/1000\n",
            "[===============================] - 0.05704021453857422 sec - loss: 83.705322265625\n",
            "Epoch: 28/1000\n",
            "[===============================] - 0.051567792892456055 sec - loss: 83.1128921508789\n",
            "Epoch: 29/1000\n",
            "[===============================] - 0.050134897232055664 sec - loss: 82.54468536376953\n",
            "Epoch: 30/1000\n",
            "[===============================] - 0.050314903259277344 sec - loss: 82.00359344482422\n",
            "Epoch: 31/1000\n",
            "[===============================] - 0.05172920227050781 sec - loss: 81.48444366455078\n",
            "Epoch: 32/1000\n",
            "[===============================] - 0.05045437812805176 sec - loss: 80.9817886352539\n",
            "Epoch: 33/1000\n",
            "[===============================] - 0.052649497985839844 sec - loss: 80.49627685546875\n",
            "Epoch: 34/1000\n",
            "[===============================] - 0.05235791206359863 sec - loss: 80.02655792236328\n",
            "Epoch: 35/1000\n",
            "[===============================] - 0.05538034439086914 sec - loss: 79.56658935546875\n",
            "Epoch: 36/1000\n",
            "[===============================] - 0.051244497299194336 sec - loss: 79.11849975585938\n",
            "Epoch: 37/1000\n",
            "[===============================] - 0.05205821990966797 sec - loss: 78.68177795410156\n",
            "Epoch: 38/1000\n",
            "[===============================] - 0.051249027252197266 sec - loss: 78.25772857666016\n",
            "Epoch: 39/1000\n",
            "[===============================] - 0.05277299880981445 sec - loss: 77.84590148925781\n",
            "Epoch: 40/1000\n",
            "[===============================] - 0.05125617980957031 sec - loss: 77.4414291381836\n",
            "Epoch: 41/1000\n",
            "[===============================] - 0.049439191818237305 sec - loss: 77.04703521728516\n",
            "Epoch: 42/1000\n",
            "[===============================] - 0.05057048797607422 sec - loss: 76.66246795654297\n",
            "Epoch: 43/1000\n",
            "[===============================] - 0.05177664756774902 sec - loss: 76.28782653808594\n",
            "Epoch: 44/1000\n",
            "[===============================] - 0.05117440223693848 sec - loss: 75.92579650878906\n",
            "Epoch: 45/1000\n",
            "[===============================] - 0.05109119415283203 sec - loss: 75.57424926757812\n",
            "Epoch: 46/1000\n",
            "[===============================] - 0.05282330513000488 sec - loss: 75.2320785522461\n",
            "Epoch: 47/1000\n",
            "[===============================] - 0.05499720573425293 sec - loss: 74.89715576171875\n",
            "Epoch: 48/1000\n",
            "[===============================] - 0.05373215675354004 sec - loss: 74.56893157958984\n",
            "Epoch: 49/1000\n",
            "[===============================] - 0.05025744438171387 sec - loss: 74.24695587158203\n",
            "Epoch: 50/1000\n",
            "[===============================] - 0.04922342300415039 sec - loss: 73.93089294433594\n",
            "Epoch: 51/1000\n",
            "[===============================] - 0.05444598197937012 sec - loss: 73.62057495117188\n",
            "Epoch: 52/1000\n",
            "[===============================] - 0.050013065338134766 sec - loss: 73.31526947021484\n",
            "Epoch: 53/1000\n",
            "[===============================] - 0.050950050354003906 sec - loss: 73.01502990722656\n",
            "Epoch: 54/1000\n",
            "[===============================] - 0.05524158477783203 sec - loss: 72.71832275390625\n",
            "Epoch: 55/1000\n",
            "[===============================] - 0.04996323585510254 sec - loss: 72.42599487304688\n",
            "Epoch: 56/1000\n",
            "[===============================] - 0.05100059509277344 sec - loss: 72.13720703125\n",
            "Epoch: 57/1000\n",
            "[===============================] - 0.04936099052429199 sec - loss: 71.8523178100586\n",
            "Epoch: 58/1000\n",
            "[===============================] - 0.05207991600036621 sec - loss: 71.56964874267578\n",
            "Epoch: 59/1000\n",
            "[===============================] - 0.05112743377685547 sec - loss: 71.28997802734375\n",
            "Epoch: 60/1000\n",
            "[===============================] - 0.04967498779296875 sec - loss: 71.0132827758789\n",
            "Epoch: 61/1000\n",
            "[===============================] - 0.05130147933959961 sec - loss: 70.73851776123047\n",
            "Epoch: 62/1000\n",
            "[===============================] - 0.05380725860595703 sec - loss: 70.46531677246094\n",
            "Epoch: 63/1000\n",
            "[===============================] - 0.04934191703796387 sec - loss: 70.19428253173828\n",
            "Epoch: 64/1000\n",
            "[===============================] - 0.05214881896972656 sec - loss: 69.9241714477539\n",
            "Epoch: 65/1000\n",
            "[===============================] - 0.06018519401550293 sec - loss: 69.65532684326172\n",
            "Epoch: 66/1000\n",
            "[===============================] - 0.05770158767700195 sec - loss: 69.38711547851562\n",
            "Epoch: 67/1000\n",
            "[===============================] - 0.048984527587890625 sec - loss: 69.119384765625\n",
            "Epoch: 68/1000\n",
            "[===============================] - 0.04979848861694336 sec - loss: 68.85191345214844\n",
            "Epoch: 69/1000\n",
            "[===============================] - 0.04989886283874512 sec - loss: 68.58447265625\n",
            "Epoch: 70/1000\n",
            "[===============================] - 0.052138566970825195 sec - loss: 68.31683349609375\n",
            "Epoch: 71/1000\n",
            "[===============================] - 0.05022907257080078 sec - loss: 68.04901885986328\n",
            "Epoch: 72/1000\n",
            "[===============================] - 0.049123525619506836 sec - loss: 67.78064727783203\n",
            "Epoch: 73/1000\n",
            "[===============================] - 0.05518817901611328 sec - loss: 67.51110076904297\n",
            "Epoch: 74/1000\n",
            "[===============================] - 0.0515289306640625 sec - loss: 67.24066925048828\n",
            "Epoch: 75/1000\n",
            "[===============================] - 0.04909873008728027 sec - loss: 66.96945190429688\n",
            "Epoch: 76/1000\n",
            "[===============================] - 0.05053973197937012 sec - loss: 66.69715881347656\n",
            "Epoch: 77/1000\n",
            "[===============================] - 0.05051088333129883 sec - loss: 66.42345428466797\n",
            "Epoch: 78/1000\n",
            "[===============================] - 0.05123281478881836 sec - loss: 66.14854431152344\n",
            "Epoch: 79/1000\n",
            "[===============================] - 0.049359798431396484 sec - loss: 65.87242889404297\n",
            "Epoch: 80/1000\n",
            "[===============================] - 0.053353309631347656 sec - loss: 65.59423065185547\n",
            "Epoch: 81/1000\n",
            "[===============================] - 0.055742740631103516 sec - loss: 65.31427764892578\n",
            "Epoch: 82/1000\n",
            "[===============================] - 0.05453324317932129 sec - loss: 65.03189849853516\n",
            "Epoch: 83/1000\n",
            "[===============================] - 0.05114436149597168 sec - loss: 64.74710845947266\n",
            "Epoch: 84/1000\n",
            "[===============================] - 0.04914689064025879 sec - loss: 64.45985412597656\n",
            "Epoch: 85/1000\n",
            "[===============================] - 0.06447052955627441 sec - loss: 64.17022705078125\n",
            "Epoch: 86/1000\n",
            "[===============================] - 0.052575111389160156 sec - loss: 63.87740707397461\n",
            "Epoch: 87/1000\n",
            "[===============================] - 0.049962520599365234 sec - loss: 63.58212661743164\n",
            "Epoch: 88/1000\n",
            "[===============================] - 0.04965329170227051 sec - loss: 63.283058166503906\n",
            "Epoch: 89/1000\n",
            "[===============================] - 0.05706429481506348 sec - loss: 62.98021697998047\n",
            "Epoch: 90/1000\n",
            "[===============================] - 0.05418062210083008 sec - loss: 62.67253494262695\n",
            "Epoch: 91/1000\n",
            "[===============================] - 0.04955029487609863 sec - loss: 62.35806655883789\n",
            "Epoch: 92/1000\n",
            "[===============================] - 0.05112862586975098 sec - loss: 62.03911209106445\n",
            "Epoch: 93/1000\n",
            "[===============================] - 0.05350327491760254 sec - loss: 61.71676254272461\n",
            "Epoch: 94/1000\n",
            "[===============================] - 0.04949164390563965 sec - loss: 61.39028549194336\n",
            "Epoch: 95/1000\n",
            "[===============================] - 0.04895925521850586 sec - loss: 61.05879211425781\n",
            "Epoch: 96/1000\n",
            "[===============================] - 0.04947519302368164 sec - loss: 60.72013854980469\n",
            "Epoch: 97/1000\n",
            "[===============================] - 0.054250478744506836 sec - loss: 60.37537384033203\n",
            "Epoch: 98/1000\n",
            "[===============================] - 0.05007576942443848 sec - loss: 60.02278137207031\n",
            "Epoch: 99/1000\n",
            "[===============================] - 0.05326724052429199 sec - loss: 59.66376876831055\n",
            "Epoch: 100/1000\n",
            "[===============================] - 0.0491023063659668 sec - loss: 59.29581069946289\n",
            "Epoch: 101/1000\n",
            "[===============================] - 0.052875518798828125 sec - loss: 58.919044494628906\n",
            "Epoch: 102/1000\n",
            "[===============================] - 0.048670291900634766 sec - loss: 58.53470993041992\n",
            "Epoch: 103/1000\n",
            "[===============================] - 0.049036502838134766 sec - loss: 58.13817596435547\n",
            "Epoch: 104/1000\n",
            "[===============================] - 0.05508136749267578 sec - loss: 57.73152542114258\n",
            "Epoch: 105/1000\n",
            "[===============================] - 0.05562305450439453 sec - loss: 57.305301666259766\n",
            "Epoch: 106/1000\n",
            "[===============================] - 0.05202770233154297 sec - loss: 56.859375\n",
            "Epoch: 107/1000\n",
            "[===============================] - 0.04907703399658203 sec - loss: 56.36409378051758\n",
            "Epoch: 108/1000\n",
            "[===============================] - 0.04997134208679199 sec - loss: 55.841529846191406\n",
            "Epoch: 109/1000\n",
            "[===============================] - 0.054131507873535156 sec - loss: 55.323692321777344\n",
            "Epoch: 110/1000\n",
            "[===============================] - 0.05081772804260254 sec - loss: 54.799537658691406\n",
            "Epoch: 111/1000\n",
            "[===============================] - 0.05031228065490723 sec - loss: 54.22142791748047\n",
            "Epoch: 112/1000\n",
            "[===============================] - 0.0525975227355957 sec - loss: 53.631378173828125\n",
            "Epoch: 113/1000\n",
            "[===============================] - 0.05394482612609863 sec - loss: 53.033634185791016\n",
            "Epoch: 114/1000\n",
            "[===============================] - 0.049794912338256836 sec - loss: 52.398963928222656\n",
            "Epoch: 115/1000\n",
            "[===============================] - 0.049551963806152344 sec - loss: 51.755027770996094\n",
            "Epoch: 116/1000\n",
            "[===============================] - 0.04915571212768555 sec - loss: 51.103824615478516\n",
            "Epoch: 117/1000\n",
            "[===============================] - 0.05305790901184082 sec - loss: 50.44700241088867\n",
            "Epoch: 118/1000\n",
            "[===============================] - 0.05132579803466797 sec - loss: 49.77787780761719\n",
            "Epoch: 119/1000\n",
            "[===============================] - 0.051462650299072266 sec - loss: 49.097694396972656\n",
            "Epoch: 120/1000\n",
            "[===============================] - 0.051096200942993164 sec - loss: 48.402587890625\n",
            "Epoch: 121/1000\n",
            "[===============================] - 0.054874420166015625 sec - loss: 47.67207717895508\n",
            "Epoch: 122/1000\n",
            "[===============================] - 0.056604862213134766 sec - loss: 46.82975387573242\n",
            "Epoch: 123/1000\n",
            "[===============================] - 0.05702066421508789 sec - loss: 45.934635162353516\n",
            "Epoch: 124/1000\n",
            "[===============================] - 0.05758023262023926 sec - loss: 45.04201889038086\n",
            "Epoch: 125/1000\n",
            "[===============================] - 0.04960894584655762 sec - loss: 44.186737060546875\n",
            "Epoch: 126/1000\n",
            "[===============================] - 0.051621198654174805 sec - loss: 43.343204498291016\n",
            "Epoch: 127/1000\n",
            "[===============================] - 0.05295205116271973 sec - loss: 42.496700286865234\n",
            "Epoch: 128/1000\n",
            "[===============================] - 0.05707740783691406 sec - loss: 41.661949157714844\n",
            "Epoch: 129/1000\n",
            "[===============================] - 0.052733659744262695 sec - loss: 40.833526611328125\n",
            "Epoch: 130/1000\n",
            "[===============================] - 0.05199766159057617 sec - loss: 39.99275207519531\n",
            "Epoch: 131/1000\n",
            "[===============================] - 0.049059152603149414 sec - loss: 39.14208221435547\n",
            "Epoch: 132/1000\n",
            "[===============================] - 0.052139997482299805 sec - loss: 38.28921127319336\n",
            "Epoch: 133/1000\n",
            "[===============================] - 0.050744056701660156 sec - loss: 37.429012298583984\n",
            "Epoch: 134/1000\n",
            "[===============================] - 0.05075812339782715 sec - loss: 36.579036712646484\n",
            "Epoch: 135/1000\n",
            "[===============================] - 0.04964733123779297 sec - loss: 35.72555923461914\n",
            "Epoch: 136/1000\n",
            "[===============================] - 0.053685665130615234 sec - loss: 34.87607955932617\n",
            "Epoch: 137/1000\n",
            "[===============================] - 0.053397417068481445 sec - loss: 34.01010513305664\n",
            "Epoch: 138/1000\n",
            "[===============================] - 0.05012631416320801 sec - loss: 33.14261245727539\n",
            "Epoch: 139/1000\n",
            "[===============================] - 0.050260305404663086 sec - loss: 32.26576614379883\n",
            "Epoch: 140/1000\n",
            "[===============================] - 0.052369117736816406 sec - loss: 31.39531707763672\n",
            "Epoch: 141/1000\n",
            "[===============================] - 0.049936532974243164 sec - loss: 30.526954650878906\n",
            "Epoch: 142/1000\n",
            "[===============================] - 0.05678272247314453 sec - loss: 29.63201332092285\n",
            "Epoch: 143/1000\n",
            "[===============================] - 0.05164623260498047 sec - loss: 28.675575256347656\n",
            "Epoch: 144/1000\n",
            "[===============================] - 0.05187869071960449 sec - loss: 27.708118438720703\n",
            "Epoch: 145/1000\n",
            "[===============================] - 0.04915285110473633 sec - loss: 26.736515045166016\n",
            "Epoch: 146/1000\n",
            "[===============================] - 0.050705671310424805 sec - loss: 25.833486557006836\n",
            "Epoch: 147/1000\n",
            "[===============================] - 0.04935455322265625 sec - loss: 24.925609588623047\n",
            "Epoch: 148/1000\n",
            "[===============================] - 0.052559852600097656 sec - loss: 24.037614822387695\n",
            "Epoch: 149/1000\n",
            "[===============================] - 0.04907679557800293 sec - loss: 23.16550064086914\n",
            "Epoch: 150/1000\n",
            "[===============================] - 0.05128169059753418 sec - loss: 22.30807876586914\n",
            "Epoch: 151/1000\n",
            "[===============================] - 0.05384492874145508 sec - loss: 21.464418411254883\n",
            "Epoch: 152/1000\n",
            "[===============================] - 0.05267739295959473 sec - loss: 20.63616371154785\n",
            "Epoch: 153/1000\n",
            "[===============================] - 0.05017423629760742 sec - loss: 19.83323860168457\n",
            "Epoch: 154/1000\n",
            "[===============================] - 0.04970264434814453 sec - loss: 19.034982681274414\n",
            "Epoch: 155/1000\n",
            "[===============================] - 0.052187204360961914 sec - loss: 18.27094268798828\n",
            "Epoch: 156/1000\n",
            "[===============================] - 0.052249908447265625 sec - loss: 17.509592056274414\n",
            "Epoch: 157/1000\n",
            "[===============================] - 0.05126523971557617 sec - loss: 16.774263381958008\n",
            "Epoch: 158/1000\n",
            "[===============================] - 0.0536656379699707 sec - loss: 16.0501651763916\n",
            "Epoch: 159/1000\n",
            "[===============================] - 0.05481457710266113 sec - loss: 15.348555564880371\n",
            "Epoch: 160/1000\n",
            "[===============================] - 0.048993825912475586 sec - loss: 14.656455039978027\n",
            "Epoch: 161/1000\n",
            "[===============================] - 0.04918718338012695 sec - loss: 13.994241714477539\n",
            "Epoch: 162/1000\n",
            "[===============================] - 0.05506086349487305 sec - loss: 13.341480255126953\n",
            "Epoch: 163/1000\n",
            "[===============================] - 0.05458784103393555 sec - loss: 12.707891464233398\n",
            "Epoch: 164/1000\n",
            "[===============================] - 0.05234670639038086 sec - loss: 12.086540222167969\n",
            "Epoch: 165/1000\n",
            "[===============================] - 0.05480003356933594 sec - loss: 11.47956657409668\n",
            "Epoch: 166/1000\n",
            "[===============================] - 0.05111527442932129 sec - loss: 10.896925926208496\n",
            "Epoch: 167/1000\n",
            "[===============================] - 0.05395770072937012 sec - loss: 10.335335731506348\n",
            "Epoch: 168/1000\n",
            "[===============================] - 0.05443120002746582 sec - loss: 9.790838241577148\n",
            "Epoch: 169/1000\n",
            "[===============================] - 0.050600528717041016 sec - loss: 9.260415077209473\n",
            "Epoch: 170/1000\n",
            "[===============================] - 0.050463199615478516 sec - loss: 8.740984916687012\n",
            "Epoch: 171/1000\n",
            "[===============================] - 0.05276632308959961 sec - loss: 8.243273735046387\n",
            "Epoch: 172/1000\n",
            "[===============================] - 0.04958629608154297 sec - loss: 7.764086723327637\n",
            "Epoch: 173/1000\n",
            "[===============================] - 0.05282855033874512 sec - loss: 7.301443576812744\n",
            "Epoch: 174/1000\n",
            "[===============================] - 0.05013751983642578 sec - loss: 6.856268405914307\n",
            "Epoch: 175/1000\n",
            "[===============================] - 0.053926706314086914 sec - loss: 6.43086576461792\n",
            "Epoch: 176/1000\n",
            "[===============================] - 0.05282402038574219 sec - loss: 6.023379325866699\n",
            "Epoch: 177/1000\n",
            "[===============================] - 0.048403263092041016 sec - loss: 5.631056308746338\n",
            "Epoch: 178/1000\n",
            "[===============================] - 0.05146622657775879 sec - loss: 5.259557723999023\n",
            "Epoch: 179/1000\n",
            "[===============================] - 0.05110907554626465 sec - loss: 4.9106035232543945\n",
            "Epoch: 180/1000\n",
            "[===============================] - 0.04858112335205078 sec - loss: 4.579107284545898\n",
            "Epoch: 181/1000\n",
            "[===============================] - 0.054360389709472656 sec - loss: 4.264742851257324\n",
            "Epoch: 182/1000\n",
            "[===============================] - 0.04812264442443848 sec - loss: 3.9618895053863525\n",
            "Epoch: 183/1000\n",
            "[===============================] - 0.05041670799255371 sec - loss: 3.6828627586364746\n",
            "Epoch: 184/1000\n",
            "[===============================] - 0.04915046691894531 sec - loss: 3.4197542667388916\n",
            "Epoch: 185/1000\n",
            "[===============================] - 0.05488133430480957 sec - loss: 3.172569990158081\n",
            "Epoch: 186/1000\n",
            "[===============================] - 0.05437302589416504 sec - loss: 2.9394052028656006\n",
            "Epoch: 187/1000\n",
            "[===============================] - 0.050510406494140625 sec - loss: 2.7176432609558105\n",
            "Epoch: 188/1000\n",
            "[===============================] - 0.05090022087097168 sec - loss: 2.510995388031006\n",
            "Epoch: 189/1000\n",
            "[===============================] - 0.04941511154174805 sec - loss: 2.31881046295166\n",
            "Epoch: 190/1000\n",
            "[===============================] - 0.051404714584350586 sec - loss: 2.1409294605255127\n",
            "Epoch: 191/1000\n",
            "[===============================] - 0.04974770545959473 sec - loss: 1.9693763256072998\n",
            "Epoch: 192/1000\n",
            "[===============================] - 0.04900550842285156 sec - loss: 1.815321922302246\n",
            "Epoch: 193/1000\n",
            "[===============================] - 0.054294586181640625 sec - loss: 1.6698801517486572\n",
            "Epoch: 194/1000\n",
            "[===============================] - 0.05250740051269531 sec - loss: 1.5356276035308838\n",
            "Epoch: 195/1000\n",
            "[===============================] - 0.0547335147857666 sec - loss: 1.4094630479812622\n",
            "Epoch: 196/1000\n",
            "[===============================] - 0.050789833068847656 sec - loss: 1.2923067808151245\n",
            "Epoch: 197/1000\n",
            "[===============================] - 0.04969024658203125 sec - loss: 1.1832126379013062\n",
            "Epoch: 198/1000\n",
            "[===============================] - 0.05292510986328125 sec - loss: 1.0835195779800415\n",
            "Epoch: 199/1000\n",
            "[===============================] - 0.048807621002197266 sec - loss: 0.9935280680656433\n",
            "Epoch: 200/1000\n",
            "[===============================] - 0.05406928062438965 sec - loss: 0.9132745862007141\n",
            "Epoch: 201/1000\n",
            "[===============================] - 0.04933738708496094 sec - loss: 0.8311008810997009\n",
            "Epoch: 202/1000\n",
            "[===============================] - 0.051537513732910156 sec - loss: 0.7590553760528564\n",
            "Epoch: 203/1000\n",
            "[===============================] - 0.052086830139160156 sec - loss: 0.6915172338485718\n",
            "Epoch: 204/1000\n",
            "[===============================] - 0.049738407135009766 sec - loss: 0.6374293565750122\n",
            "Epoch: 205/1000\n",
            "[===============================] - 0.053731679916381836 sec - loss: 0.5836509466171265\n",
            "Epoch: 206/1000\n",
            "[===============================] - 0.058562278747558594 sec - loss: 0.5348729491233826\n",
            "Epoch: 207/1000\n",
            "[===============================] - 0.053298234939575195 sec - loss: 0.49076589941978455\n",
            "Epoch: 208/1000\n",
            "[===============================] - 0.05318570137023926 sec - loss: 0.44647663831710815\n",
            "Epoch: 209/1000\n",
            "[===============================] - 0.04956364631652832 sec - loss: 0.41480374336242676\n",
            "Epoch: 210/1000\n",
            "[===============================] - 0.05412459373474121 sec - loss: 0.3841605484485626\n",
            "Epoch: 211/1000\n",
            "[===============================] - 0.05199265480041504 sec - loss: 0.34251895546913147\n",
            "Epoch: 212/1000\n",
            "[===============================] - 0.0515904426574707 sec - loss: 0.3195019066333771\n",
            "Epoch: 213/1000\n",
            "[===============================] - 0.04889988899230957 sec - loss: 0.2892712354660034\n",
            "Epoch: 214/1000\n",
            "[===============================] - 0.05086660385131836 sec - loss: 0.2700693607330322\n",
            "Epoch: 215/1000\n",
            "[===============================] - 0.04907393455505371 sec - loss: 0.25404059886932373\n",
            "Epoch: 216/1000\n",
            "[===============================] - 0.04904603958129883 sec - loss: 0.23727327585220337\n",
            "Epoch: 217/1000\n",
            "[===============================] - 0.050096988677978516 sec - loss: 0.22564342617988586\n",
            "Epoch: 218/1000\n",
            "[===============================] - 0.05090618133544922 sec - loss: 0.21510951220989227\n",
            "Epoch: 219/1000\n",
            "[===============================] - 0.04947257041931152 sec - loss: 0.2040102183818817\n",
            "Epoch: 220/1000\n",
            "[===============================] - 0.05538749694824219 sec - loss: 0.19532392919063568\n",
            "Epoch: 221/1000\n",
            "[===============================] - 0.04919099807739258 sec - loss: 0.18753354251384735\n",
            "Epoch: 222/1000\n",
            "[===============================] - 0.051168203353881836 sec - loss: 0.17990796267986298\n",
            "Epoch: 223/1000\n",
            "[===============================] - 0.04909563064575195 sec - loss: 0.17314746975898743\n",
            "Epoch: 224/1000\n",
            "[===============================] - 0.052336692810058594 sec - loss: 0.16691003739833832\n",
            "Epoch: 225/1000\n",
            "[===============================] - 0.04919910430908203 sec - loss: 0.16082918643951416\n",
            "Epoch: 226/1000\n",
            "[===============================] - 0.051102399826049805 sec - loss: 0.15548335015773773\n",
            "Epoch: 227/1000\n",
            "[===============================] - 0.051753997802734375 sec - loss: 0.1526261866092682\n",
            "Epoch: 228/1000\n",
            "[===============================] - 0.051741600036621094 sec - loss: 0.14719252288341522\n",
            "Epoch: 229/1000\n",
            "[===============================] - 0.05043315887451172 sec - loss: 0.14481323957443237\n",
            "Epoch: 230/1000\n",
            "[===============================] - 0.05133628845214844 sec - loss: 0.14089511334896088\n",
            "Epoch: 231/1000\n",
            "[===============================] - 0.05285501480102539 sec - loss: 0.13838474452495575\n",
            "Epoch: 232/1000\n",
            "[===============================] - 0.05036449432373047 sec - loss: 0.21285177767276764\n",
            "Epoch: 233/1000\n",
            "[===============================] - 0.0568242073059082 sec - loss: 0.20379877090454102\n",
            "Epoch: 234/1000\n",
            "[===============================] - 0.05381488800048828 sec - loss: 0.16470785439014435\n",
            "Epoch: 235/1000\n",
            "[===============================] - 0.05549430847167969 sec - loss: 0.23610259592533112\n",
            "Epoch: 236/1000\n",
            "[===============================] - 0.05057024955749512 sec - loss: 0.2506450116634369\n",
            "Epoch: 237/1000\n",
            "[===============================] - 0.052489280700683594 sec - loss: 0.14161376655101776\n",
            "Epoch: 238/1000\n",
            "[===============================] - 0.04824042320251465 sec - loss: 0.13127225637435913\n",
            "Epoch: 239/1000\n",
            "[===============================] - 0.05313682556152344 sec - loss: 0.26893141865730286\n",
            "Epoch: 240/1000\n",
            "[===============================] - 0.04875326156616211 sec - loss: 0.8220990896224976\n",
            "Epoch: 241/1000\n",
            "[===============================] - 0.05241060256958008 sec - loss: 0.1430344134569168\n",
            "Epoch: 242/1000\n",
            "[===============================] - 0.050362348556518555 sec - loss: 0.13516007363796234\n",
            "Epoch: 243/1000\n",
            "[===============================] - 0.051482439041137695 sec - loss: 0.13021327555179596\n",
            "Epoch: 244/1000\n",
            "[===============================] - 0.052820444107055664 sec - loss: 0.1261766254901886\n",
            "Epoch: 245/1000\n",
            "[===============================] - 0.05575752258300781 sec - loss: 0.13959312438964844\n",
            "Epoch: 246/1000\n",
            "[===============================] - 0.049936532974243164 sec - loss: 0.20933762192726135\n",
            "Epoch: 247/1000\n",
            "[===============================] - 0.049997806549072266 sec - loss: 0.17462337017059326\n",
            "Epoch: 248/1000\n",
            "[===============================] - 0.05392336845397949 sec - loss: 0.17594477534294128\n",
            "Epoch: 249/1000\n",
            "[===============================] - 0.05189824104309082 sec - loss: 0.19455119967460632\n",
            "Epoch: 250/1000\n",
            "[===============================] - 0.049164772033691406 sec - loss: 0.22032581269741058\n",
            "Epoch: 251/1000\n",
            "[===============================] - 0.05245161056518555 sec - loss: 0.17072659730911255\n",
            "Epoch: 252/1000\n",
            "[===============================] - 0.04973626136779785 sec - loss: 0.16369156539440155\n",
            "Epoch: 253/1000\n",
            "[===============================] - 0.05448794364929199 sec - loss: 0.30183207988739014\n",
            "Epoch: 254/1000\n",
            "[===============================] - 0.05006742477416992 sec - loss: 0.18009620904922485\n",
            "Epoch: 255/1000\n",
            "[===============================] - 0.049271583557128906 sec - loss: 0.13103234767913818\n",
            "Epoch: 256/1000\n",
            "[===============================] - 0.05164647102355957 sec - loss: 0.13701945543289185\n",
            "Epoch: 257/1000\n",
            "[===============================] - 0.05962872505187988 sec - loss: 1.0120967626571655\n",
            "Epoch: 258/1000\n",
            "[===============================] - 0.05662655830383301 sec - loss: 0.14800584316253662\n",
            "Epoch: 259/1000\n",
            "[===============================] - 0.049837350845336914 sec - loss: 0.13380728662014008\n",
            "Epoch: 260/1000\n",
            "[===============================] - 0.053565263748168945 sec - loss: 0.1284405142068863\n",
            "Epoch: 261/1000\n",
            "[===============================] - 0.049523353576660156 sec - loss: 0.12292830646038055\n",
            "Epoch: 262/1000\n",
            "[===============================] - 0.04998326301574707 sec - loss: 0.1329612284898758\n",
            "Epoch: 263/1000\n",
            "[===============================] - 0.05122709274291992 sec - loss: 0.21125106513500214\n",
            "Epoch: 264/1000\n",
            "[===============================] - 0.05633664131164551 sec - loss: 0.21331046521663666\n",
            "Epoch: 265/1000\n",
            "[===============================] - 0.05104804039001465 sec - loss: 0.19822320342063904\n",
            "Epoch: 266/1000\n",
            "[===============================] - 0.051549434661865234 sec - loss: 0.23394577205181122\n",
            "Epoch: 267/1000\n",
            "[===============================] - 0.04919123649597168 sec - loss: 0.21386858820915222\n",
            "Epoch: 268/1000\n",
            "[===============================] - 0.053193092346191406 sec - loss: 0.21418683230876923\n",
            "Epoch: 269/1000\n",
            "[===============================] - 0.05344200134277344 sec - loss: 0.17612306773662567\n",
            "Epoch: 270/1000\n",
            "[===============================] - 0.05188345909118652 sec - loss: 0.4191904067993164\n",
            "Epoch: 271/1000\n",
            "[===============================] - 0.05296134948730469 sec - loss: 0.41285616159439087\n",
            "Epoch: 272/1000\n",
            "[===============================] - 0.05199170112609863 sec - loss: 0.3797602951526642\n",
            "Epoch: 273/1000\n",
            "[===============================] - 0.050631046295166016 sec - loss: 0.8377691507339478\n",
            "Epoch: 274/1000\n",
            "[===============================] - 0.05276799201965332 sec - loss: 0.31504473090171814\n",
            "Epoch: 275/1000\n",
            "[===============================] - 0.051245927810668945 sec - loss: 0.9508435726165771\n",
            "Epoch: 276/1000\n",
            "[===============================] - 0.052397727966308594 sec - loss: 0.11530529707670212\n",
            "Epoch: 277/1000\n",
            "[===============================] - 0.051096200942993164 sec - loss: 0.10795361548662186\n",
            "Epoch: 278/1000\n",
            "[===============================] - 0.060398101806640625 sec - loss: 0.23172827064990997\n",
            "Epoch: 279/1000\n",
            "[===============================] - 0.05137968063354492 sec - loss: 4.833201885223389\n",
            "Epoch: 280/1000\n",
            "[===============================] - 0.05453157424926758 sec - loss: 0.14903080463409424\n",
            "Epoch: 281/1000\n",
            "[===============================] - 0.05221295356750488 sec - loss: 0.1435418576002121\n",
            "Epoch: 282/1000\n",
            "[===============================] - 0.0505373477935791 sec - loss: 0.1424337774515152\n",
            "Epoch: 283/1000\n",
            "[===============================] - 0.05462503433227539 sec - loss: 0.1353575438261032\n",
            "Epoch: 284/1000\n",
            "[===============================] - 0.05141162872314453 sec - loss: 0.11169718950986862\n",
            "Epoch: 285/1000\n",
            "[===============================] - 0.049207210540771484 sec - loss: 0.14961783587932587\n",
            "Epoch: 286/1000\n",
            "[===============================] - 0.04888272285461426 sec - loss: 2.142404079437256\n",
            "Epoch: 287/1000\n",
            "[===============================] - 0.051056623458862305 sec - loss: 0.14322085678577423\n",
            "Epoch: 288/1000\n",
            "[===============================] - 0.050752878189086914 sec - loss: 1.1843774318695068\n",
            "Epoch: 289/1000\n",
            "[===============================] - 0.055429697036743164 sec - loss: 0.15360869467258453\n",
            "Epoch: 290/1000\n",
            "[===============================] - 0.05277681350708008 sec - loss: 2.649358034133911\n",
            "Epoch: 291/1000\n",
            "[===============================] - 0.0523679256439209 sec - loss: 0.15267625451087952\n",
            "Epoch: 292/1000\n",
            "[===============================] - 0.05034470558166504 sec - loss: 0.46428176760673523\n",
            "Epoch: 293/1000\n",
            "[===============================] - 0.07051825523376465 sec - loss: 0.20645254850387573\n",
            "Epoch: 294/1000\n",
            "[===============================] - 0.056131839752197266 sec - loss: 0.7131586670875549\n",
            "Epoch: 295/1000\n",
            "[===============================] - 0.057648658752441406 sec - loss: 8.000816345214844\n",
            "Epoch: 296/1000\n",
            "[===============================] - 0.06030774116516113 sec - loss: 0.16508010029792786\n",
            "Epoch: 297/1000\n",
            "[===============================] - 0.050206661224365234 sec - loss: 0.1515510231256485\n",
            "Epoch: 298/1000\n",
            "[===============================] - 0.055913686752319336 sec - loss: 0.11440823972225189\n",
            "Epoch: 299/1000\n",
            "[===============================] - 0.05129218101501465 sec - loss: 0.12389196455478668\n",
            "Epoch: 300/1000\n",
            "[===============================] - 0.05095243453979492 sec - loss: 0.6533631086349487\n",
            "Epoch: 301/1000\n",
            "[===============================] - 0.049346923828125 sec - loss: 0.13770349323749542\n",
            "Epoch: 302/1000\n",
            "[===============================] - 0.05310869216918945 sec - loss: 0.11402598768472672\n",
            "Epoch: 303/1000\n",
            "[===============================] - 0.04877614974975586 sec - loss: 0.1069868728518486\n",
            "Epoch: 304/1000\n",
            "[===============================] - 0.049779653549194336 sec - loss: 3.969259262084961\n",
            "Epoch: 305/1000\n",
            "[===============================] - 0.05376100540161133 sec - loss: 0.1777808964252472\n",
            "Epoch: 306/1000\n",
            "[===============================] - 0.05550670623779297 sec - loss: 0.9467020630836487\n",
            "Epoch: 307/1000\n",
            "[===============================] - 0.05037975311279297 sec - loss: 0.1919921338558197\n",
            "Epoch: 308/1000\n",
            "[===============================] - 0.049509286880493164 sec - loss: 1.2103464603424072\n",
            "Epoch: 309/1000\n",
            "[===============================] - 0.04984784126281738 sec - loss: 4.0428056716918945\n",
            "Epoch: 310/1000\n",
            "[===============================] - 0.05222821235656738 sec - loss: 0.1946077048778534\n",
            "Epoch: 311/1000\n",
            "[===============================] - 0.04964709281921387 sec - loss: 0.5127676129341125\n",
            "Epoch: 312/1000\n",
            "[===============================] - 0.049163818359375 sec - loss: 0.37586838006973267\n",
            "Epoch: 313/1000\n",
            "[===============================] - 0.05176520347595215 sec - loss: 0.07716923952102661\n",
            "Epoch: 314/1000\n",
            "[===============================] - 0.05165266990661621 sec - loss: 2.8105156421661377\n",
            "Epoch: 315/1000\n",
            "[===============================] - 0.04973626136779785 sec - loss: 0.19655822217464447\n",
            "Epoch: 316/1000\n",
            "[===============================] - 0.05357980728149414 sec - loss: 6.091180324554443\n",
            "Epoch: 317/1000\n",
            "[===============================] - 0.04895210266113281 sec - loss: 0.11452168971300125\n",
            "Epoch: 318/1000\n",
            "[===============================] - 0.05176854133605957 sec - loss: 0.10186614096164703\n",
            "Epoch: 319/1000\n",
            "[===============================] - 0.05032968521118164 sec - loss: 0.572843074798584\n",
            "Epoch: 320/1000\n",
            "[===============================] - 0.04909181594848633 sec - loss: 0.18913164734840393\n",
            "Epoch: 321/1000\n",
            "[===============================] - 0.05740976333618164 sec - loss: 0.19078479707241058\n",
            "Epoch: 322/1000\n",
            "[===============================] - 0.05314230918884277 sec - loss: 0.10095854848623276\n",
            "Epoch: 323/1000\n",
            "[===============================] - 0.049046993255615234 sec - loss: 2.6351685523986816\n",
            "Epoch: 324/1000\n",
            "[===============================] - 0.05084037780761719 sec - loss: 1.036087155342102\n",
            "Epoch: 325/1000\n",
            "[===============================] - 0.05327415466308594 sec - loss: 6.621524333953857\n",
            "Epoch: 326/1000\n",
            "[===============================] - 0.05490994453430176 sec - loss: 0.08048952370882034\n",
            "Epoch: 327/1000\n",
            "[===============================] - 0.05382704734802246 sec - loss: 0.0753638967871666\n",
            "Epoch: 328/1000\n",
            "[===============================] - 0.05594444274902344 sec - loss: 0.16559934616088867\n",
            "Epoch: 329/1000\n",
            "[===============================] - 0.05387568473815918 sec - loss: 0.20812973380088806\n",
            "Epoch: 330/1000\n",
            "[===============================] - 0.05104255676269531 sec - loss: 0.05930276960134506\n",
            "Epoch: 331/1000\n",
            "[===============================] - 0.04964613914489746 sec - loss: 0.5290254950523376\n",
            "Epoch: 332/1000\n",
            "[===============================] - 0.04873967170715332 sec - loss: 7.895052909851074\n",
            "Epoch: 333/1000\n",
            "[===============================] - 0.05266427993774414 sec - loss: 0.13625295460224152\n",
            "Epoch: 334/1000\n",
            "[===============================] - 0.0517880916595459 sec - loss: 0.11306577920913696\n",
            "Epoch: 335/1000\n",
            "[===============================] - 0.05508995056152344 sec - loss: 0.1396210640668869\n",
            "Epoch: 336/1000\n",
            "[===============================] - 0.04914522171020508 sec - loss: 0.2723696529865265\n",
            "Epoch: 337/1000\n",
            "[===============================] - 0.05227041244506836 sec - loss: 0.43243688344955444\n",
            "Epoch: 338/1000\n",
            "[===============================] - 0.05103635787963867 sec - loss: 0.1205364391207695\n",
            "Epoch: 339/1000\n",
            "[===============================] - 0.0527188777923584 sec - loss: 1.172340989112854\n",
            "Epoch: 340/1000\n",
            "[===============================] - 0.05174756050109863 sec - loss: 9.755929946899414\n",
            "Epoch: 341/1000\n",
            "[===============================] - 0.05382823944091797 sec - loss: 0.16849841177463531\n",
            "Epoch: 342/1000\n",
            "[===============================] - 0.05153155326843262 sec - loss: 0.11712947487831116\n",
            "Epoch: 343/1000\n",
            "[===============================] - 0.049875736236572266 sec - loss: 0.1262589544057846\n",
            "Epoch: 344/1000\n",
            "[===============================] - 0.05151247978210449 sec - loss: 0.5084282159805298\n",
            "Epoch: 345/1000\n",
            "[===============================] - 0.05454659461975098 sec - loss: 0.12774157524108887\n",
            "Epoch: 346/1000\n",
            "[===============================] - 0.05050396919250488 sec - loss: 0.20212282240390778\n",
            "Epoch: 347/1000\n",
            "[===============================] - 0.050882816314697266 sec - loss: 0.22652147710323334\n",
            "Epoch: 348/1000\n",
            "[===============================] - 0.050925254821777344 sec - loss: 0.42034828662872314\n",
            "Epoch: 349/1000\n",
            "[===============================] - 0.053917884826660156 sec - loss: 2.5754075050354004\n",
            "Epoch: 350/1000\n",
            "[===============================] - 0.04989194869995117 sec - loss: 1.3248088359832764\n",
            "Epoch: 351/1000\n",
            "[===============================] - 0.049852609634399414 sec - loss: 3.136237859725952\n",
            "Epoch: 352/1000\n",
            "[===============================] - 0.04896736145019531 sec - loss: 0.127238929271698\n",
            "Epoch: 353/1000\n",
            "[===============================] - 0.05184221267700195 sec - loss: 1.2676811218261719\n",
            "Epoch: 354/1000\n",
            "[===============================] - 0.05436134338378906 sec - loss: 0.3016306161880493\n",
            "Epoch: 355/1000\n",
            "[===============================] - 0.05063891410827637 sec - loss: 0.17696569859981537\n",
            "Epoch: 356/1000\n",
            "[===============================] - 0.0520322322845459 sec - loss: 4.170788764953613\n",
            "Epoch: 357/1000\n",
            "[===============================] - 0.054903268814086914 sec - loss: 0.22382578253746033\n",
            "Epoch: 358/1000\n",
            "[===============================] - 0.05647134780883789 sec - loss: 24.748058319091797\n",
            "Epoch: 359/1000\n",
            "[===============================] - 0.0509343147277832 sec - loss: 0.311730295419693\n",
            "Epoch: 360/1000\n",
            "[===============================] - 0.05128955841064453 sec - loss: 0.319229394197464\n",
            "Epoch: 361/1000\n",
            "[===============================] - 0.050783634185791016 sec - loss: 0.2859170138835907\n",
            "Epoch: 362/1000\n",
            "[===============================] - 0.04936027526855469 sec - loss: 0.12867392599582672\n",
            "Epoch: 363/1000\n",
            "[===============================] - 0.04989337921142578 sec - loss: 0.37376803159713745\n",
            "Epoch: 364/1000\n",
            "[===============================] - 0.055304527282714844 sec - loss: 9.756464004516602\n",
            "Epoch: 365/1000\n",
            "[===============================] - 0.05216670036315918 sec - loss: 0.1236708015203476\n",
            "Epoch: 366/1000\n",
            "[===============================] - 0.05139923095703125 sec - loss: 0.10038642585277557\n",
            "Epoch: 367/1000\n",
            "[===============================] - 0.05219554901123047 sec - loss: 0.09917370975017548\n",
            "Epoch: 368/1000\n",
            "[===============================] - 0.05468297004699707 sec - loss: 0.109212726354599\n",
            "Epoch: 369/1000\n",
            "[===============================] - 0.054198265075683594 sec - loss: 0.13404904305934906\n",
            "Epoch: 370/1000\n",
            "[===============================] - 0.05048823356628418 sec - loss: 0.15292592346668243\n",
            "Epoch: 371/1000\n",
            "[===============================] - 0.05133175849914551 sec - loss: 0.092980295419693\n",
            "Epoch: 372/1000\n",
            "[===============================] - 0.0570223331451416 sec - loss: 0.05982299521565437\n",
            "Epoch: 373/1000\n",
            "[===============================] - 0.05675077438354492 sec - loss: 1.913844108581543\n",
            "Epoch: 374/1000\n",
            "[===============================] - 0.05346202850341797 sec - loss: 10.216104507446289\n",
            "Epoch: 375/1000\n",
            "[===============================] - 0.051132917404174805 sec - loss: 0.11702590435743332\n",
            "Epoch: 376/1000\n",
            "[===============================] - 0.05558609962463379 sec - loss: 0.09735036641359329\n",
            "Epoch: 377/1000\n",
            "[===============================] - 0.05063462257385254 sec - loss: 0.09114965796470642\n",
            "Epoch: 378/1000\n",
            "[===============================] - 0.05313849449157715 sec - loss: 0.10935591161251068\n",
            "Epoch: 379/1000\n",
            "[===============================] - 0.052186012268066406 sec - loss: 0.2030681073665619\n",
            "Epoch: 380/1000\n",
            "[===============================] - 0.054509878158569336 sec - loss: 0.1927400380373001\n",
            "Epoch: 381/1000\n",
            "[===============================] - 0.049868106842041016 sec - loss: 0.2295333445072174\n",
            "Epoch: 382/1000\n",
            "[===============================] - 0.04999709129333496 sec - loss: 0.16551700234413147\n",
            "Epoch: 383/1000\n",
            "[===============================] - 0.05115652084350586 sec - loss: 0.17483003437519073\n",
            "Epoch: 384/1000\n",
            "[===============================] - 0.05532336235046387 sec - loss: 8.0747652053833\n",
            "Epoch: 385/1000\n",
            "[===============================] - 0.053344011306762695 sec - loss: 0.21525351703166962\n",
            "Epoch: 386/1000\n",
            "[===============================] - 0.04986858367919922 sec - loss: 0.40134596824645996\n",
            "Epoch: 387/1000\n",
            "[===============================] - 0.05382871627807617 sec - loss: 0.18955031037330627\n",
            "Epoch: 388/1000\n",
            "[===============================] - 0.051038265228271484 sec - loss: 0.19993777573108673\n",
            "Epoch: 389/1000\n",
            "[===============================] - 0.05020022392272949 sec - loss: 0.24051877856254578\n",
            "Epoch: 390/1000\n",
            "[===============================] - 0.05107426643371582 sec - loss: 0.173540860414505\n",
            "Epoch: 391/1000\n",
            "[===============================] - 0.052747488021850586 sec - loss: 9.737035751342773\n",
            "Epoch: 392/1000\n",
            "[===============================] - 0.05455470085144043 sec - loss: 0.16299806535243988\n",
            "Epoch: 393/1000\n",
            "[===============================] - 0.05141282081604004 sec - loss: 0.13734309375286102\n",
            "Epoch: 394/1000\n",
            "[===============================] - 0.04946780204772949 sec - loss: 0.12477932870388031\n",
            "Epoch: 395/1000\n",
            "[===============================] - 0.05624532699584961 sec - loss: 0.10991714894771576\n",
            "Epoch: 396/1000\n",
            "[===============================] - 0.05107378959655762 sec - loss: 0.11787538230419159\n",
            "Epoch: 397/1000\n",
            "[===============================] - 0.05102229118347168 sec - loss: 0.15660326182842255\n",
            "Epoch: 398/1000\n",
            "[===============================] - 0.05206179618835449 sec - loss: 0.1475926637649536\n",
            "Epoch: 399/1000\n",
            "[===============================] - 0.05101490020751953 sec - loss: 2.608257532119751\n",
            "Epoch: 400/1000\n",
            "[===============================] - 0.04960346221923828 sec - loss: 0.4321805238723755\n",
            "Epoch: 401/1000\n",
            "[===============================] - 0.051360368728637695 sec - loss: 9.11776351928711\n",
            "Epoch: 402/1000\n",
            "[===============================] - 0.05244278907775879 sec - loss: 0.09255200624465942\n",
            "Epoch: 403/1000\n",
            "[===============================] - 0.05504727363586426 sec - loss: 0.0782412439584732\n",
            "Epoch: 404/1000\n",
            "[===============================] - 0.05174112319946289 sec - loss: 0.17770709097385406\n",
            "Epoch: 405/1000\n",
            "[===============================] - 0.05169200897216797 sec - loss: 0.65582275390625\n",
            "Epoch: 406/1000\n",
            "[===============================] - 0.05029034614562988 sec - loss: 0.12587571144104004\n",
            "Epoch: 407/1000\n",
            "[===============================] - 0.058242082595825195 sec - loss: 0.14218249917030334\n",
            "Epoch: 408/1000\n",
            "[===============================] - 0.05522871017456055 sec - loss: 0.06782394647598267\n",
            "Epoch: 409/1000\n",
            "[===============================] - 0.05360245704650879 sec - loss: 0.5401129126548767\n",
            "Epoch: 410/1000\n",
            "[===============================] - 0.05704212188720703 sec - loss: 10.179754257202148\n",
            "Epoch: 411/1000\n",
            "[===============================] - 0.055685997009277344 sec - loss: 0.14643819630146027\n",
            "Epoch: 412/1000\n",
            "[===============================] - 0.05229520797729492 sec - loss: 0.1177196204662323\n",
            "Epoch: 413/1000\n",
            "[===============================] - 0.05260777473449707 sec - loss: 0.10457199066877365\n",
            "Epoch: 414/1000\n",
            "[===============================] - 0.0536348819732666 sec - loss: 0.1298980712890625\n",
            "Epoch: 415/1000\n",
            "[===============================] - 0.051467180252075195 sec - loss: 0.26116567850112915\n",
            "Epoch: 416/1000\n",
            "[===============================] - 0.053171396255493164 sec - loss: 0.25942912697792053\n",
            "Epoch: 417/1000\n",
            "[===============================] - 0.056664228439331055 sec - loss: 0.12482957541942596\n",
            "Epoch: 418/1000\n",
            "[===============================] - 0.05413961410522461 sec - loss: 0.24938136339187622\n",
            "Epoch: 419/1000\n",
            "[===============================] - 0.05399203300476074 sec - loss: 2.7210254669189453\n",
            "Epoch: 420/1000\n",
            "[===============================] - 0.05257010459899902 sec - loss: 8.939432144165039\n",
            "Epoch: 421/1000\n",
            "[===============================] - 0.0523531436920166 sec - loss: 0.12982934713363647\n",
            "Epoch: 422/1000\n",
            "[===============================] - 0.05407142639160156 sec - loss: 0.10579464584589005\n",
            "Epoch: 423/1000\n",
            "[===============================] - 0.05171942710876465 sec - loss: 0.10622092336416245\n",
            "Epoch: 424/1000\n",
            "[===============================] - 0.05357241630554199 sec - loss: 0.12140899151563644\n",
            "Epoch: 425/1000\n",
            "[===============================] - 0.06405806541442871 sec - loss: 0.1494443565607071\n",
            "Epoch: 426/1000\n",
            "[===============================] - 0.06052517890930176 sec - loss: 0.16525979340076447\n",
            "Epoch: 427/1000\n",
            "[===============================] - 0.05011129379272461 sec - loss: 0.12704239785671234\n",
            "Epoch: 428/1000\n",
            "[===============================] - 0.05112409591674805 sec - loss: 0.2694490849971771\n",
            "Epoch: 429/1000\n",
            "[===============================] - 0.05506467819213867 sec - loss: 8.592154502868652\n",
            "Epoch: 430/1000\n",
            "[===============================] - 0.05188131332397461 sec - loss: 0.21087639033794403\n",
            "Epoch: 431/1000\n",
            "[===============================] - 0.05007290840148926 sec - loss: 0.2814778685569763\n",
            "Epoch: 432/1000\n",
            "[===============================] - 0.05222511291503906 sec - loss: 0.14100734889507294\n",
            "Epoch: 433/1000\n",
            "[===============================] - 0.05130505561828613 sec - loss: 0.12144813686609268\n",
            "Epoch: 434/1000\n",
            "[===============================] - 0.051322221755981445 sec - loss: 0.16434258222579956\n",
            "Epoch: 435/1000\n",
            "[===============================] - 0.05096268653869629 sec - loss: 0.2964157462120056\n",
            "Epoch: 436/1000\n",
            "[===============================] - 0.049425601959228516 sec - loss: 0.45204126834869385\n",
            "Epoch: 437/1000\n",
            "[===============================] - 0.0535275936126709 sec - loss: 11.510007858276367\n",
            "Epoch: 438/1000\n",
            "[===============================] - 0.04971647262573242 sec - loss: 0.14457204937934875\n",
            "Epoch: 439/1000\n",
            "[===============================] - 0.052758216857910156 sec - loss: 0.1090451255440712\n",
            "Epoch: 440/1000\n",
            "[===============================] - 0.05374479293823242 sec - loss: 0.09134233742952347\n",
            "Epoch: 441/1000\n",
            "[===============================] - 0.05745720863342285 sec - loss: 0.07774072140455246\n",
            "Epoch: 442/1000\n",
            "[===============================] - 0.050324440002441406 sec - loss: 0.06213449314236641\n",
            "Epoch: 443/1000\n",
            "[===============================] - 0.050022125244140625 sec - loss: 0.06488475948572159\n",
            "Epoch: 444/1000\n",
            "[===============================] - 0.052404165267944336 sec - loss: 0.2085365206003189\n",
            "Epoch: 445/1000\n",
            "[===============================] - 0.05069613456726074 sec - loss: 0.21580882370471954\n",
            "Epoch: 446/1000\n",
            "[===============================] - 0.05079030990600586 sec - loss: 1.307473063468933\n",
            "Epoch: 447/1000\n",
            "[===============================] - 0.05217242240905762 sec - loss: 5.922133445739746\n",
            "Epoch: 448/1000\n",
            "[===============================] - 0.05396771430969238 sec - loss: 0.2696922719478607\n",
            "Epoch: 449/1000\n",
            "[===============================] - 0.053945302963256836 sec - loss: 0.46185970306396484\n",
            "Epoch: 450/1000\n",
            "[===============================] - 0.05024409294128418 sec - loss: 0.24608759582042694\n",
            "Epoch: 451/1000\n",
            "[===============================] - 0.04979133605957031 sec - loss: 1.2529957294464111\n",
            "Epoch: 452/1000\n",
            "[===============================] - 0.05466628074645996 sec - loss: 0.0793594941496849\n",
            "Epoch: 453/1000\n",
            "[===============================] - 0.05129504203796387 sec - loss: 1.1081843376159668\n",
            "Epoch: 454/1000\n",
            "[===============================] - 0.05262875556945801 sec - loss: 8.56466293334961\n",
            "Epoch: 455/1000\n",
            "[===============================] - 0.05173182487487793 sec - loss: 0.12934556603431702\n",
            "Epoch: 456/1000\n",
            "[===============================] - 0.05442166328430176 sec - loss: 0.11399421840906143\n",
            "Epoch: 457/1000\n",
            "[===============================] - 0.051728010177612305 sec - loss: 0.11098036170005798\n",
            "Epoch: 458/1000\n",
            "[===============================] - 0.051645517349243164 sec - loss: 0.10398660600185394\n",
            "Epoch: 459/1000\n",
            "[===============================] - 0.05087399482727051 sec - loss: 0.2200368195772171\n",
            "Epoch: 460/1000\n",
            "[===============================] - 0.0532681941986084 sec - loss: 0.23421397805213928\n",
            "Epoch: 461/1000\n",
            "[===============================] - 0.0507817268371582 sec - loss: 0.15425477921962738\n",
            "Epoch: 462/1000\n",
            "[===============================] - 0.0536189079284668 sec - loss: 1.2806119918823242\n",
            "Epoch: 463/1000\n",
            "[===============================] - 0.05410480499267578 sec - loss: 8.165582656860352\n",
            "Epoch: 464/1000\n",
            "[===============================] - 0.05324244499206543 sec - loss: 0.20942789316177368\n",
            "Epoch: 465/1000\n",
            "[===============================] - 0.049124717712402344 sec - loss: 0.21461229026317596\n",
            "Epoch: 466/1000\n",
            "[===============================] - 0.0492396354675293 sec - loss: 0.1764088273048401\n",
            "Epoch: 467/1000\n",
            "[===============================] - 0.052095651626586914 sec - loss: 0.0979139432311058\n",
            "Epoch: 468/1000\n",
            "[===============================] - 0.059648990631103516 sec - loss: 0.06143854185938835\n",
            "Epoch: 469/1000\n",
            "[===============================] - 0.05083894729614258 sec - loss: 0.21655920147895813\n",
            "Epoch: 470/1000\n",
            "[===============================] - 0.05675625801086426 sec - loss: 2.3381307125091553\n",
            "Epoch: 471/1000\n",
            "[===============================] - 0.05471038818359375 sec - loss: 3.4613125324249268\n",
            "Epoch: 472/1000\n",
            "[===============================] - 0.05750131607055664 sec - loss: 0.20834487676620483\n",
            "Epoch: 473/1000\n",
            "[===============================] - 0.051285505294799805 sec - loss: 0.2476550191640854\n",
            "Epoch: 474/1000\n",
            "[===============================] - 0.04982638359069824 sec - loss: 0.17128978669643402\n",
            "Epoch: 475/1000\n",
            "[===============================] - 0.05876564979553223 sec - loss: 1.1248810291290283\n",
            "Epoch: 476/1000\n",
            "[===============================] - 0.05156350135803223 sec - loss: 6.174139976501465\n",
            "Epoch: 477/1000\n",
            "[===============================] - 0.05279684066772461 sec - loss: 0.34536293148994446\n",
            "Epoch: 478/1000\n",
            "[===============================] - 0.05106472969055176 sec - loss: 0.3729292154312134\n",
            "Epoch: 479/1000\n",
            "[===============================] - 0.05349993705749512 sec - loss: 0.21994221210479736\n",
            "Epoch: 480/1000\n",
            "[===============================] - 0.0495302677154541 sec - loss: 0.10541023313999176\n",
            "Epoch: 481/1000\n",
            "[===============================] - 0.05069279670715332 sec - loss: 0.28580600023269653\n",
            "Epoch: 482/1000\n",
            "[===============================] - 0.05197429656982422 sec - loss: 0.4072335362434387\n",
            "Epoch: 483/1000\n",
            "[===============================] - 0.05338764190673828 sec - loss: 10.738492965698242\n",
            "Epoch: 484/1000\n",
            "[===============================] - 0.05107474327087402 sec - loss: 0.1482064425945282\n",
            "Epoch: 485/1000\n",
            "[===============================] - 0.05023837089538574 sec - loss: 0.11440356075763702\n",
            "Epoch: 486/1000\n",
            "[===============================] - 0.050488948822021484 sec - loss: 0.10785365104675293\n",
            "Epoch: 487/1000\n",
            "[===============================] - 0.058324337005615234 sec - loss: 0.08272792398929596\n",
            "Epoch: 488/1000\n",
            "[===============================] - 0.05154705047607422 sec - loss: 0.12449368089437485\n",
            "Epoch: 489/1000\n",
            "[===============================] - 0.05090785026550293 sec - loss: 0.5745400190353394\n",
            "Epoch: 490/1000\n",
            "[===============================] - 0.0493316650390625 sec - loss: 0.07490749657154083\n",
            "Epoch: 491/1000\n",
            "[===============================] - 0.053848981857299805 sec - loss: 0.11401908099651337\n",
            "Epoch: 492/1000\n",
            "[===============================] - 0.06607961654663086 sec - loss: 2.2130720615386963\n",
            "Epoch: 493/1000\n",
            "[===============================] - 0.05627584457397461 sec - loss: 1.2648451328277588\n",
            "Epoch: 494/1000\n",
            "[===============================] - 0.055016517639160156 sec - loss: 5.451234340667725\n",
            "Epoch: 495/1000\n",
            "[===============================] - 0.05359911918640137 sec - loss: 0.2995723485946655\n",
            "Epoch: 496/1000\n",
            "[===============================] - 0.054515838623046875 sec - loss: 0.21799248456954956\n",
            "Epoch: 497/1000\n",
            "[===============================] - 0.05133938789367676 sec - loss: 0.09748443961143494\n",
            "Epoch: 498/1000\n",
            "[===============================] - 0.053442955017089844 sec - loss: 0.1333421915769577\n",
            "Epoch: 499/1000\n",
            "[===============================] - 0.050461769104003906 sec - loss: 0.2691001892089844\n",
            "Epoch: 500/1000\n",
            "[===============================] - 0.05153179168701172 sec - loss: 1.1165846586227417\n",
            "Epoch: 501/1000\n",
            "[===============================] - 0.05135321617126465 sec - loss: 8.307255744934082\n",
            "Epoch: 502/1000\n",
            "[===============================] - 0.05303335189819336 sec - loss: 0.2210858017206192\n",
            "Epoch: 503/1000\n",
            "[===============================] - 0.049146175384521484 sec - loss: 0.18874885141849518\n",
            "Epoch: 504/1000\n",
            "[===============================] - 0.05094265937805176 sec - loss: 0.1511555016040802\n",
            "Epoch: 505/1000\n",
            "[===============================] - 0.05272364616394043 sec - loss: 0.11602409929037094\n",
            "Epoch: 506/1000\n",
            "[===============================] - 0.05767965316772461 sec - loss: 0.364332914352417\n",
            "Epoch: 507/1000\n",
            "[===============================] - 0.049491167068481445 sec - loss: 0.05029407516121864\n",
            "Epoch: 508/1000\n",
            "[===============================] - 0.051690101623535156 sec - loss: 0.4820004105567932\n",
            "Epoch: 509/1000\n",
            "[===============================] - 0.05062532424926758 sec - loss: 2.684345006942749\n",
            "Epoch: 510/1000\n",
            "[===============================] - 0.055786848068237305 sec - loss: 1.478679895401001\n",
            "Epoch: 511/1000\n",
            "[===============================] - 0.054166555404663086 sec - loss: 4.685359954833984\n",
            "Epoch: 512/1000\n",
            "[===============================] - 0.05109453201293945 sec - loss: 0.0436209961771965\n",
            "Epoch: 513/1000\n",
            "[===============================] - 0.05633878707885742 sec - loss: 0.15166431665420532\n",
            "Epoch: 514/1000\n",
            "[===============================] - 0.05303049087524414 sec - loss: 0.16135206818580627\n",
            "Epoch: 515/1000\n",
            "[===============================] - 0.05287051200866699 sec - loss: 0.0976397916674614\n",
            "Epoch: 516/1000\n",
            "[===============================] - 0.052410125732421875 sec - loss: 1.3988699913024902\n",
            "Epoch: 517/1000\n",
            "[===============================] - 0.05427241325378418 sec - loss: 0.7600936889648438\n",
            "Epoch: 518/1000\n",
            "[===============================] - 0.05613303184509277 sec - loss: 9.038307189941406\n",
            "Epoch: 519/1000\n",
            "[===============================] - 0.04934358596801758 sec - loss: 0.35847505927085876\n",
            "Epoch: 520/1000\n",
            "[===============================] - 0.05112719535827637 sec - loss: 0.1386185586452484\n",
            "Epoch: 521/1000\n",
            "[===============================] - 0.05255937576293945 sec - loss: 0.09271671622991562\n",
            "Epoch: 522/1000\n",
            "[===============================] - 0.04938387870788574 sec - loss: 0.04747932404279709\n",
            "Epoch: 523/1000\n",
            "[===============================] - 0.04999208450317383 sec - loss: 0.1616177260875702\n",
            "Epoch: 524/1000\n",
            "[===============================] - 0.05197858810424805 sec - loss: 0.35646572709083557\n",
            "Epoch: 525/1000\n",
            "[===============================] - 0.059400320053100586 sec - loss: 0.12222462892532349\n",
            "Epoch: 526/1000\n",
            "[===============================] - 0.053314208984375 sec - loss: 0.4796827733516693\n",
            "Epoch: 527/1000\n",
            "[===============================] - 0.051579952239990234 sec - loss: 9.574211120605469\n",
            "Epoch: 528/1000\n",
            "[===============================] - 0.05200362205505371 sec - loss: 0.08706103265285492\n",
            "Epoch: 529/1000\n",
            "[===============================] - 0.05385637283325195 sec - loss: 0.08207561820745468\n",
            "Epoch: 530/1000\n",
            "[===============================] - 0.05315279960632324 sec - loss: 0.13501714169979095\n",
            "Epoch: 531/1000\n",
            "[===============================] - 0.05473828315734863 sec - loss: 0.10004489868879318\n",
            "Epoch: 532/1000\n",
            "[===============================] - 0.056755781173706055 sec - loss: 0.09879087656736374\n",
            "Epoch: 533/1000\n",
            "[===============================] - 0.052445411682128906 sec - loss: 0.7771176099777222\n",
            "Epoch: 534/1000\n",
            "[===============================] - 0.05581402778625488 sec - loss: 0.10307076573371887\n",
            "Epoch: 535/1000\n",
            "[===============================] - 0.04941916465759277 sec - loss: 0.2897065281867981\n",
            "Epoch: 536/1000\n",
            "[===============================] - 0.051809072494506836 sec - loss: 9.392799377441406\n",
            "Epoch: 537/1000\n",
            "[===============================] - 0.04972648620605469 sec - loss: 0.10620163381099701\n",
            "Epoch: 538/1000\n",
            "[===============================] - 0.049175262451171875 sec - loss: 0.0844384953379631\n",
            "Epoch: 539/1000\n",
            "[===============================] - 0.05078387260437012 sec - loss: 0.08730799704790115\n",
            "Epoch: 540/1000\n",
            "[===============================] - 0.05100131034851074 sec - loss: 0.154133141040802\n",
            "Epoch: 541/1000\n",
            "[===============================] - 0.05147361755371094 sec - loss: 1.1207702159881592\n",
            "Epoch: 542/1000\n",
            "[===============================] - 0.04886603355407715 sec - loss: 0.12728308141231537\n",
            "Epoch: 543/1000\n",
            "[===============================] - 0.049941062927246094 sec - loss: 0.1128571555018425\n",
            "Epoch: 544/1000\n",
            "[===============================] - 0.059267520904541016 sec - loss: 0.1282212883234024\n",
            "Epoch: 545/1000\n",
            "[===============================] - 0.050421714782714844 sec - loss: 2.619689464569092\n",
            "Epoch: 546/1000\n",
            "[===============================] - 0.0517117977142334 sec - loss: 1.18189537525177\n",
            "Epoch: 547/1000\n",
            "[===============================] - 0.05338764190673828 sec - loss: 5.729949474334717\n",
            "Epoch: 548/1000\n",
            "[===============================] - 0.05536913871765137 sec - loss: 0.04994775727391243\n",
            "Epoch: 549/1000\n",
            "[===============================] - 0.05099749565124512 sec - loss: 0.1112854853272438\n",
            "Epoch: 550/1000\n",
            "[===============================] - 0.05100893974304199 sec - loss: 0.16522446274757385\n",
            "Epoch: 551/1000\n",
            "[===============================] - 0.05008816719055176 sec - loss: 0.1542697250843048\n",
            "Epoch: 552/1000\n",
            "[===============================] - 0.060538291931152344 sec - loss: 0.05015731230378151\n",
            "Epoch: 553/1000\n",
            "[===============================] - 0.05158400535583496 sec - loss: 2.061631441116333\n",
            "Epoch: 554/1000\n",
            "[===============================] - 0.05193185806274414 sec - loss: 4.063268184661865\n",
            "Epoch: 555/1000\n",
            "[===============================] - 0.04930591583251953 sec - loss: 0.10457838326692581\n",
            "Epoch: 556/1000\n",
            "[===============================] - 0.05327153205871582 sec - loss: 0.09498747438192368\n",
            "Epoch: 557/1000\n",
            "[===============================] - 0.05088305473327637 sec - loss: 0.10446193069219589\n",
            "Epoch: 558/1000\n",
            "[===============================] - 0.051256418228149414 sec - loss: 3.0930542945861816\n",
            "Epoch: 559/1000\n",
            "[===============================] - 0.04925799369812012 sec - loss: 0.18057258427143097\n",
            "Epoch: 560/1000\n",
            "[===============================] - 0.05487632751464844 sec - loss: 2.3346238136291504\n",
            "Epoch: 561/1000\n",
            "[===============================] - 0.05000424385070801 sec - loss: 0.562471330165863\n",
            "Epoch: 562/1000\n",
            "[===============================] - 0.05440044403076172 sec - loss: 0.6372502446174622\n",
            "Epoch: 563/1000\n",
            "[===============================] - 0.05715298652648926 sec - loss: 0.13767249882221222\n",
            "Epoch: 564/1000\n",
            "[===============================] - 0.05066251754760742 sec - loss: 2.2434632778167725\n",
            "Epoch: 565/1000\n",
            "[===============================] - 0.05071091651916504 sec - loss: 3.787018299102783\n",
            "Epoch: 566/1000\n",
            "[===============================] - 0.05045795440673828 sec - loss: 0.08582711964845657\n",
            "Epoch: 567/1000\n",
            "[===============================] - 0.05485844612121582 sec - loss: 0.07988079637289047\n",
            "Epoch: 568/1000\n",
            "[===============================] - 0.051854848861694336 sec - loss: 0.3095007538795471\n",
            "Epoch: 569/1000\n",
            "[===============================] - 0.04957437515258789 sec - loss: 2.0828588008880615\n",
            "Epoch: 570/1000\n",
            "[===============================] - 0.0496373176574707 sec - loss: 0.4667302966117859\n",
            "Epoch: 571/1000\n",
            "[===============================] - 0.05128765106201172 sec - loss: 4.221830368041992\n",
            "Epoch: 572/1000\n",
            "[===============================] - 0.051763057708740234 sec - loss: 0.09572368860244751\n",
            "Epoch: 573/1000\n",
            "[===============================] - 0.0512087345123291 sec - loss: 0.7953923940658569\n",
            "Epoch: 574/1000\n",
            "[===============================] - 0.05019736289978027 sec - loss: 0.3597818911075592\n",
            "Epoch: 575/1000\n",
            "[===============================] - 0.05570721626281738 sec - loss: 0.2707229256629944\n",
            "Epoch: 576/1000\n",
            "[===============================] - 0.05410432815551758 sec - loss: 0.08539114892482758\n",
            "Epoch: 577/1000\n",
            "[===============================] - 0.05134010314941406 sec - loss: 5.242630481719971\n",
            "Epoch: 578/1000\n",
            "[===============================] - 0.05199909210205078 sec - loss: 0.17831365764141083\n",
            "Epoch: 579/1000\n",
            "[===============================] - 0.05354905128479004 sec - loss: 0.6885377764701843\n",
            "Epoch: 580/1000\n",
            "[===============================] - 0.05075812339782715 sec - loss: 0.04782818257808685\n",
            "Epoch: 581/1000\n",
            "[===============================] - 0.05164027214050293 sec - loss: 0.6837162971496582\n",
            "Epoch: 582/1000\n",
            "[===============================] - 0.05692338943481445 sec - loss: 3.348564863204956\n",
            "Epoch: 583/1000\n",
            "[===============================] - 0.05743813514709473 sec - loss: 0.8544897437095642\n",
            "Epoch: 584/1000\n",
            "[===============================] - 0.05020260810852051 sec - loss: 0.08192940056324005\n",
            "Epoch: 585/1000\n",
            "[===============================] - 0.05003666877746582 sec - loss: 1.5376471281051636\n",
            "Epoch: 586/1000\n",
            "[===============================] - 0.054744720458984375 sec - loss: 0.6832242608070374\n",
            "Epoch: 587/1000\n",
            "[===============================] - 0.0528101921081543 sec - loss: 6.81339693069458\n",
            "Epoch: 588/1000\n",
            "[===============================] - 0.05162382125854492 sec - loss: 0.04039428383111954\n",
            "Epoch: 589/1000\n",
            "[===============================] - 0.04982447624206543 sec - loss: 0.07091791927814484\n",
            "Epoch: 590/1000\n",
            "[===============================] - 0.05791807174682617 sec - loss: 0.11663301289081573\n",
            "Epoch: 591/1000\n",
            "[===============================] - 0.05231666564941406 sec - loss: 0.17559941112995148\n",
            "Epoch: 592/1000\n",
            "[===============================] - 0.05166053771972656 sec - loss: 0.13165318965911865\n",
            "Epoch: 593/1000\n",
            "[===============================] - 0.05053973197937012 sec - loss: 0.3812028765678406\n",
            "Epoch: 594/1000\n",
            "[===============================] - 0.05392718315124512 sec - loss: 4.754785537719727\n",
            "Epoch: 595/1000\n",
            "[===============================] - 0.05209708213806152 sec - loss: 0.24689948558807373\n",
            "Epoch: 596/1000\n",
            "[===============================] - 0.05424904823303223 sec - loss: 1.3430531024932861\n",
            "Epoch: 597/1000\n",
            "[===============================] - 0.05030512809753418 sec - loss: 0.4217788875102997\n",
            "Epoch: 598/1000\n",
            "[===============================] - 0.05176854133605957 sec - loss: 0.13405758142471313\n",
            "Epoch: 599/1000\n",
            "[===============================] - 0.051912546157836914 sec - loss: 0.09288247674703598\n",
            "Epoch: 600/1000\n",
            "[===============================] - 0.05109691619873047 sec - loss: 1.4232327938079834\n",
            "Epoch: 601/1000\n",
            "[===============================] - 0.05727338790893555 sec - loss: 9.704655647277832\n",
            "Epoch: 602/1000\n",
            "[===============================] - 0.05385136604309082 sec - loss: 0.16601264476776123\n",
            "Epoch: 603/1000\n",
            "[===============================] - 0.0507659912109375 sec - loss: 0.13209351897239685\n",
            "Epoch: 604/1000\n",
            "[===============================] - 0.0543360710144043 sec - loss: 0.0899096354842186\n",
            "Epoch: 605/1000\n",
            "[===============================] - 0.05435442924499512 sec - loss: 0.050048522651195526\n",
            "Epoch: 606/1000\n",
            "[===============================] - 0.051045894622802734 sec - loss: 0.21108205616474152\n",
            "Epoch: 607/1000\n",
            "[===============================] - 0.05201292037963867 sec - loss: 0.04649219289422035\n",
            "Epoch: 608/1000\n",
            "[===============================] - 0.0537872314453125 sec - loss: 0.5407387614250183\n",
            "Epoch: 609/1000\n",
            "[===============================] - 0.05267596244812012 sec - loss: 0.183495432138443\n",
            "Epoch: 610/1000\n",
            "[===============================] - 0.05156207084655762 sec - loss: 2.8404788970947266\n",
            "Epoch: 611/1000\n",
            "[===============================] - 0.05351662635803223 sec - loss: 0.5843920111656189\n",
            "Epoch: 612/1000\n",
            "[===============================] - 0.04972195625305176 sec - loss: 2.3222105503082275\n",
            "Epoch: 613/1000\n",
            "[===============================] - 0.05167269706726074 sec - loss: 0.8760926127433777\n",
            "Epoch: 614/1000\n",
            "[===============================] - 0.04912066459655762 sec - loss: 0.3203011155128479\n",
            "Epoch: 615/1000\n",
            "[===============================] - 0.04970979690551758 sec - loss: 0.16526275873184204\n",
            "Epoch: 616/1000\n",
            "[===============================] - 0.05295157432556152 sec - loss: 2.1030433177948\n",
            "Epoch: 617/1000\n",
            "[===============================] - 0.05777692794799805 sec - loss: 3.818761110305786\n",
            "Epoch: 618/1000\n",
            "[===============================] - 0.050299882888793945 sec - loss: 0.11668068915605545\n",
            "Epoch: 619/1000\n",
            "[===============================] - 0.05076003074645996 sec - loss: 0.1101778969168663\n",
            "Epoch: 620/1000\n",
            "[===============================] - 0.054212331771850586 sec - loss: 0.16539934277534485\n",
            "Epoch: 621/1000\n",
            "[===============================] - 0.052474260330200195 sec - loss: 1.4600284099578857\n",
            "Epoch: 622/1000\n",
            "[===============================] - 0.05609011650085449 sec - loss: 0.5594725012779236\n",
            "Epoch: 623/1000\n",
            "[===============================] - 0.05065345764160156 sec - loss: 7.89353084564209\n",
            "Epoch: 624/1000\n",
            "[===============================] - 0.0550074577331543 sec - loss: 0.054146237671375275\n",
            "Epoch: 625/1000\n",
            "[===============================] - 0.05100083351135254 sec - loss: 0.08249092102050781\n",
            "Epoch: 626/1000\n",
            "[===============================] - 0.053680419921875 sec - loss: 0.08510232716798782\n",
            "Epoch: 627/1000\n",
            "[===============================] - 0.054012298583984375 sec - loss: 0.10656024515628815\n",
            "Epoch: 628/1000\n",
            "[===============================] - 0.0518949031829834 sec - loss: 0.4475708305835724\n",
            "Epoch: 629/1000\n",
            "[===============================] - 0.05156707763671875 sec - loss: 0.5021133422851562\n",
            "Epoch: 630/1000\n",
            "[===============================] - 0.053684234619140625 sec - loss: 0.12742136418819427\n",
            "Epoch: 631/1000\n",
            "[===============================] - 0.04981517791748047 sec - loss: 1.21394944190979\n",
            "Epoch: 632/1000\n",
            "[===============================] - 0.05354022979736328 sec - loss: 10.362502098083496\n",
            "Epoch: 633/1000\n",
            "[===============================] - 0.05056166648864746 sec - loss: 0.08019088953733444\n",
            "Epoch: 634/1000\n",
            "[===============================] - 0.05251455307006836 sec - loss: 0.057394709438085556\n",
            "Epoch: 635/1000\n",
            "[===============================] - 0.054616689682006836 sec - loss: 0.06124343350529671\n",
            "Epoch: 636/1000\n",
            "[===============================] - 0.05422091484069824 sec - loss: 0.05172628536820412\n",
            "Epoch: 637/1000\n",
            "[===============================] - 0.056383609771728516 sec - loss: 0.05713799223303795\n",
            "Epoch: 638/1000\n",
            "[===============================] - 0.05159711837768555 sec - loss: 13.921913146972656\n",
            "Epoch: 639/1000\n",
            "[===============================] - 0.05785393714904785 sec - loss: 0.14060193300247192\n",
            "Epoch: 640/1000\n",
            "[===============================] - 0.05272173881530762 sec - loss: 0.3222041726112366\n",
            "Epoch: 641/1000\n",
            "[===============================] - 0.05059409141540527 sec - loss: 0.14094726741313934\n",
            "Epoch: 642/1000\n",
            "[===============================] - 0.05188870429992676 sec - loss: 0.08643375337123871\n",
            "Epoch: 643/1000\n",
            "[===============================] - 0.05569291114807129 sec - loss: 7.428155422210693\n",
            "Epoch: 644/1000\n",
            "[===============================] - 0.05158591270446777 sec - loss: 0.08580271154642105\n",
            "Epoch: 645/1000\n",
            "[===============================] - 0.0531158447265625 sec - loss: 0.19058600068092346\n",
            "Epoch: 646/1000\n",
            "[===============================] - 0.05023074150085449 sec - loss: 0.2876725494861603\n",
            "Epoch: 647/1000\n",
            "[===============================] - 0.05369067192077637 sec - loss: 0.3415556848049164\n",
            "Epoch: 648/1000\n",
            "[===============================] - 0.052496910095214844 sec - loss: 0.25902360677719116\n",
            "Epoch: 649/1000\n",
            "[===============================] - 0.050151824951171875 sec - loss: 0.07112782448530197\n",
            "Epoch: 650/1000\n",
            "[===============================] - 0.05095791816711426 sec - loss: 0.04128968343138695\n",
            "Epoch: 651/1000\n",
            "[===============================] - 0.054915428161621094 sec - loss: 2.9005539417266846\n",
            "Epoch: 652/1000\n",
            "[===============================] - 0.05009102821350098 sec - loss: 3.846050500869751\n",
            "Epoch: 653/1000\n",
            "[===============================] - 0.050008535385131836 sec - loss: 0.09849581867456436\n",
            "Epoch: 654/1000\n",
            "[===============================] - 0.05164813995361328 sec - loss: 0.055477604269981384\n",
            "Epoch: 655/1000\n",
            "[===============================] - 0.05452704429626465 sec - loss: 0.1485150307416916\n",
            "Epoch: 656/1000\n",
            "[===============================] - 0.054024457931518555 sec - loss: 0.2165987193584442\n",
            "Epoch: 657/1000\n",
            "[===============================] - 0.050260305404663086 sec - loss: 0.42762255668640137\n",
            "Epoch: 658/1000\n",
            "[===============================] - 0.059218645095825195 sec - loss: 10.46406364440918\n",
            "Epoch: 659/1000\n",
            "[===============================] - 0.05656695365905762 sec - loss: 0.13976430892944336\n",
            "Epoch: 660/1000\n",
            "[===============================] - 0.05187511444091797 sec - loss: 0.09064330160617828\n",
            "Epoch: 661/1000\n",
            "[===============================] - 0.051438093185424805 sec - loss: 0.06941691040992737\n",
            "Epoch: 662/1000\n",
            "[===============================] - 0.052755117416381836 sec - loss: 0.05455624312162399\n",
            "Epoch: 663/1000\n",
            "[===============================] - 0.051789045333862305 sec - loss: 0.03997223824262619\n",
            "Epoch: 664/1000\n",
            "[===============================] - 0.05144023895263672 sec - loss: 0.05501248314976692\n",
            "Epoch: 665/1000\n",
            "[===============================] - 0.05011320114135742 sec - loss: 0.05544654279947281\n",
            "Epoch: 666/1000\n",
            "[===============================] - 0.05543375015258789 sec - loss: 0.0900827944278717\n",
            "Epoch: 667/1000\n",
            "[===============================] - 0.05086255073547363 sec - loss: 10.072064399719238\n",
            "Epoch: 668/1000\n",
            "[===============================] - 0.0496981143951416 sec - loss: 0.06458009034395218\n",
            "Epoch: 669/1000\n",
            "[===============================] - 0.055486440658569336 sec - loss: 0.051977112889289856\n",
            "Epoch: 670/1000\n",
            "[===============================] - 0.05481529235839844 sec - loss: 0.04748442769050598\n",
            "Epoch: 671/1000\n",
            "[===============================] - 0.05296969413757324 sec - loss: 0.05109884962439537\n",
            "Epoch: 672/1000\n",
            "[===============================] - 0.049329280853271484 sec - loss: 0.06670920550823212\n",
            "Epoch: 673/1000\n",
            "[===============================] - 0.0502774715423584 sec - loss: 0.0671178549528122\n",
            "Epoch: 674/1000\n",
            "[===============================] - 0.053787946701049805 sec - loss: 0.12768606841564178\n",
            "Epoch: 675/1000\n",
            "[===============================] - 0.05004692077636719 sec - loss: 3.9114573001861572\n",
            "Epoch: 676/1000\n",
            "[===============================] - 0.050557851791381836 sec - loss: 0.5492920875549316\n",
            "Epoch: 677/1000\n",
            "[===============================] - 0.05447983741760254 sec - loss: 0.63211989402771\n",
            "Epoch: 678/1000\n",
            "[===============================] - 0.05351424217224121 sec - loss: 0.0989069789648056\n",
            "Epoch: 679/1000\n",
            "[===============================] - 0.0548093318939209 sec - loss: 0.8998176455497742\n",
            "Epoch: 680/1000\n",
            "[===============================] - 0.053491830825805664 sec - loss: 3.0713086128234863\n",
            "Epoch: 681/1000\n",
            "[===============================] - 0.05018734931945801 sec - loss: 0.1622622311115265\n",
            "Epoch: 682/1000\n",
            "[===============================] - 0.05792999267578125 sec - loss: 1.2435145378112793\n",
            "Epoch: 683/1000\n",
            "[===============================] - 0.051674842834472656 sec - loss: 1.2998628616333008\n",
            "Epoch: 684/1000\n",
            "[===============================] - 0.05111217498779297 sec - loss: 0.10388010740280151\n",
            "Epoch: 685/1000\n",
            "[===============================] - 0.053260087966918945 sec - loss: 0.7399063110351562\n",
            "Epoch: 686/1000\n",
            "[===============================] - 0.05678057670593262 sec - loss: 2.3732070922851562\n",
            "Epoch: 687/1000\n",
            "[===============================] - 0.05216026306152344 sec - loss: 1.7387568950653076\n",
            "Epoch: 688/1000\n",
            "[===============================] - 0.05326676368713379 sec - loss: 1.1708831787109375\n",
            "Epoch: 689/1000\n",
            "[===============================] - 0.061885833740234375 sec - loss: 0.0940803736448288\n",
            "Epoch: 690/1000\n",
            "[===============================] - 0.05508732795715332 sec - loss: 0.24052195250988007\n",
            "Epoch: 691/1000\n",
            "[===============================] - 0.05017423629760742 sec - loss: 0.13059310615062714\n",
            "Epoch: 692/1000\n",
            "[===============================] - 0.04945230484008789 sec - loss: 10.865358352661133\n",
            "Epoch: 693/1000\n",
            "[===============================] - 0.0530238151550293 sec - loss: 0.08221668750047684\n",
            "Epoch: 694/1000\n",
            "[===============================] - 0.05695343017578125 sec - loss: 0.051112182438373566\n",
            "Epoch: 695/1000\n",
            "[===============================] - 0.060868024826049805 sec - loss: 0.045906372368335724\n",
            "Epoch: 696/1000\n",
            "[===============================] - 0.05045509338378906 sec - loss: 0.09824632108211517\n",
            "Epoch: 697/1000\n",
            "[===============================] - 0.05610084533691406 sec - loss: 1.1748883724212646\n",
            "Epoch: 698/1000\n",
            "[===============================] - 0.05375361442565918 sec - loss: 0.04678477719426155\n",
            "Epoch: 699/1000\n",
            "[===============================] - 0.05345582962036133 sec - loss: 0.038096532225608826\n",
            "Epoch: 700/1000\n",
            "[===============================] - 0.054291486740112305 sec - loss: 0.04143783077597618\n",
            "Epoch: 701/1000\n",
            "[===============================] - 0.052269935607910156 sec - loss: 0.3094790577888489\n",
            "Epoch: 702/1000\n",
            "[===============================] - 0.05085587501525879 sec - loss: 8.897000312805176\n",
            "Epoch: 703/1000\n",
            "[===============================] - 0.050740957260131836 sec - loss: 0.09598378837108612\n",
            "Epoch: 704/1000\n",
            "[===============================] - 0.0575258731842041 sec - loss: 0.08090271800756454\n",
            "Epoch: 705/1000\n",
            "[===============================] - 0.05334830284118652 sec - loss: 0.07982403039932251\n",
            "Epoch: 706/1000\n",
            "[===============================] - 0.05392742156982422 sec - loss: 0.09353591501712799\n",
            "Epoch: 707/1000\n",
            "[===============================] - 0.05105185508728027 sec - loss: 0.10894414037466049\n",
            "Epoch: 708/1000\n",
            "[===============================] - 0.06063437461853027 sec - loss: 0.42016592621803284\n",
            "Epoch: 709/1000\n",
            "[===============================] - 0.051178932189941406 sec - loss: 0.12745796144008636\n",
            "Epoch: 710/1000\n",
            "[===============================] - 0.050423383712768555 sec - loss: 1.45187509059906\n",
            "Epoch: 711/1000\n",
            "[===============================] - 0.04935622215270996 sec - loss: 1.9437299966812134\n",
            "Epoch: 712/1000\n",
            "[===============================] - 0.05267524719238281 sec - loss: 6.724062919616699\n",
            "Epoch: 713/1000\n",
            "[===============================] - 0.05077075958251953 sec - loss: 0.03145648166537285\n",
            "Epoch: 714/1000\n",
            "[===============================] - 0.05364274978637695 sec - loss: 0.026539262384176254\n",
            "Epoch: 715/1000\n",
            "[===============================] - 0.0524897575378418 sec - loss: 0.022004852071404457\n",
            "Epoch: 716/1000\n",
            "[===============================] - 0.05137133598327637 sec - loss: 0.022584225982427597\n",
            "Epoch: 717/1000\n",
            "[===============================] - 0.05010628700256348 sec - loss: 0.08994128555059433\n",
            "Epoch: 718/1000\n",
            "[===============================] - 0.04862070083618164 sec - loss: 0.8622588515281677\n",
            "Epoch: 719/1000\n",
            "[===============================] - 0.05255532264709473 sec - loss: 0.4622795581817627\n",
            "Epoch: 720/1000\n",
            "[===============================] - 0.04899096488952637 sec - loss: 3.417396306991577\n",
            "Epoch: 721/1000\n",
            "[===============================] - 0.05027270317077637 sec - loss: 1.046907663345337\n",
            "Epoch: 722/1000\n",
            "[===============================] - 0.050873517990112305 sec - loss: 0.23598191142082214\n",
            "Epoch: 723/1000\n",
            "[===============================] - 0.05465888977050781 sec - loss: 0.28179967403411865\n",
            "Epoch: 724/1000\n",
            "[===============================] - 0.05384206771850586 sec - loss: 0.12892082333564758\n",
            "Epoch: 725/1000\n",
            "[===============================] - 0.050273895263671875 sec - loss: 9.976552963256836\n",
            "Epoch: 726/1000\n",
            "[===============================] - 0.05006551742553711 sec - loss: 0.06604957580566406\n",
            "Epoch: 727/1000\n",
            "[===============================] - 0.053354740142822266 sec - loss: 0.05819522961974144\n",
            "Epoch: 728/1000\n",
            "[===============================] - 0.04993104934692383 sec - loss: 0.05814428627490997\n",
            "Epoch: 729/1000\n",
            "[===============================] - 0.05272555351257324 sec - loss: 0.05346924811601639\n",
            "Epoch: 730/1000\n",
            "[===============================] - 0.052243947982788086 sec - loss: 0.2024502009153366\n",
            "Epoch: 731/1000\n",
            "[===============================] - 0.06095170974731445 sec - loss: 0.7572743892669678\n",
            "Epoch: 732/1000\n",
            "[===============================] - 0.05251455307006836 sec - loss: 0.05163521319627762\n",
            "Epoch: 733/1000\n",
            "[===============================] - 0.05484175682067871 sec - loss: 0.11449157446622849\n",
            "Epoch: 734/1000\n",
            "[===============================] - 0.05559372901916504 sec - loss: 1.0437573194503784\n",
            "Epoch: 735/1000\n",
            "[===============================] - 0.06010580062866211 sec - loss: 7.797657012939453\n",
            "Epoch: 736/1000\n",
            "[===============================] - 0.057863473892211914 sec - loss: 0.12161325663328171\n",
            "Epoch: 737/1000\n",
            "[===============================] - 0.05059695243835449 sec - loss: 0.12054842710494995\n",
            "Epoch: 738/1000\n",
            "[===============================] - 0.05420255661010742 sec - loss: 0.12661515176296234\n",
            "Epoch: 739/1000\n",
            "[===============================] - 0.05133986473083496 sec - loss: 0.13923902809619904\n",
            "Epoch: 740/1000\n",
            "[===============================] - 0.05178976058959961 sec - loss: 1.3345705270767212\n",
            "Epoch: 741/1000\n",
            "[===============================] - 0.05029916763305664 sec - loss: 0.3467883765697479\n",
            "Epoch: 742/1000\n",
            "[===============================] - 0.057210683822631836 sec - loss: 0.11070806533098221\n",
            "Epoch: 743/1000\n",
            "[===============================] - 0.0513918399810791 sec - loss: 2.512486219406128\n",
            "Epoch: 744/1000\n",
            "[===============================] - 0.05258965492248535 sec - loss: 2.859998941421509\n",
            "Epoch: 745/1000\n",
            "[===============================] - 0.05024147033691406 sec - loss: 0.04710754007101059\n",
            "Epoch: 746/1000\n",
            "[===============================] - 0.05178046226501465 sec - loss: 0.05394720658659935\n",
            "Epoch: 747/1000\n",
            "[===============================] - 0.05013227462768555 sec - loss: 0.10209225118160248\n",
            "Epoch: 748/1000\n",
            "[===============================] - 0.04973578453063965 sec - loss: 0.3263092339038849\n",
            "Epoch: 749/1000\n",
            "[===============================] - 0.05054330825805664 sec - loss: 6.9827046394348145\n",
            "Epoch: 750/1000\n",
            "[===============================] - 0.059001922607421875 sec - loss: 0.216458261013031\n",
            "Epoch: 751/1000\n",
            "[===============================] - 0.055559396743774414 sec - loss: 0.19165079295635223\n",
            "Epoch: 752/1000\n",
            "[===============================] - 0.05949521064758301 sec - loss: 0.18620827794075012\n",
            "Epoch: 753/1000\n",
            "[===============================] - 0.05871319770812988 sec - loss: 0.1542157083749771\n",
            "Epoch: 754/1000\n",
            "[===============================] - 0.056940555572509766 sec - loss: 0.1391964554786682\n",
            "Epoch: 755/1000\n",
            "[===============================] - 0.05512666702270508 sec - loss: 1.1159881353378296\n",
            "Epoch: 756/1000\n",
            "[===============================] - 0.05637073516845703 sec - loss: 2.69028639793396\n",
            "Epoch: 757/1000\n",
            "[===============================] - 0.06232047080993652 sec - loss: 1.1739888191223145\n",
            "Epoch: 758/1000\n",
            "[===============================] - 0.05652952194213867 sec - loss: 0.10972096025943756\n",
            "Epoch: 759/1000\n",
            "[===============================] - 0.05240488052368164 sec - loss: 0.761017918586731\n",
            "Epoch: 760/1000\n",
            "[===============================] - 0.052574872970581055 sec - loss: 0.21571242809295654\n",
            "Epoch: 761/1000\n",
            "[===============================] - 0.05218958854675293 sec - loss: 9.396143913269043\n",
            "Epoch: 762/1000\n",
            "[===============================] - 0.05124640464782715 sec - loss: 0.046345729380846024\n",
            "Epoch: 763/1000\n",
            "[===============================] - 0.052318572998046875 sec - loss: 0.04863157868385315\n",
            "Epoch: 764/1000\n",
            "[===============================] - 0.05510282516479492 sec - loss: 0.05973478779196739\n",
            "Epoch: 765/1000\n",
            "[===============================] - 0.04982280731201172 sec - loss: 0.04768181964755058\n",
            "Epoch: 766/1000\n",
            "[===============================] - 0.04999065399169922 sec - loss: 0.07275472581386566\n",
            "Epoch: 767/1000\n",
            "[===============================] - 0.05016970634460449 sec - loss: 1.053853154182434\n",
            "Epoch: 768/1000\n",
            "[===============================] - 0.05357861518859863 sec - loss: 0.0403207466006279\n",
            "Epoch: 769/1000\n",
            "[===============================] - 0.049956560134887695 sec - loss: 0.39375391602516174\n",
            "Epoch: 770/1000\n",
            "[===============================] - 0.05655646324157715 sec - loss: 1.5613261461257935\n",
            "Epoch: 771/1000\n",
            "[===============================] - 0.05097699165344238 sec - loss: 6.730159282684326\n",
            "Epoch: 772/1000\n",
            "[===============================] - 0.061444759368896484 sec - loss: 0.07320725172758102\n",
            "Epoch: 773/1000\n",
            "[===============================] - 0.053144216537475586 sec - loss: 0.05000542476773262\n",
            "Epoch: 774/1000\n",
            "[===============================] - 0.05261349678039551 sec - loss: 0.02827465534210205\n",
            "Epoch: 775/1000\n",
            "[===============================] - 0.050786495208740234 sec - loss: 0.025419680401682854\n",
            "Epoch: 776/1000\n",
            "[===============================] - 0.05393028259277344 sec - loss: 0.122944675385952\n",
            "Epoch: 777/1000\n",
            "[===============================] - 0.05114603042602539 sec - loss: 0.7795431017875671\n",
            "Epoch: 778/1000\n",
            "[===============================] - 0.05204200744628906 sec - loss: 0.10270193964242935\n",
            "Epoch: 779/1000\n",
            "[===============================] - 0.05409979820251465 sec - loss: 2.4674782752990723\n",
            "Epoch: 780/1000\n",
            "[===============================] - 0.05923581123352051 sec - loss: 10.20362663269043\n",
            "Epoch: 781/1000\n",
            "[===============================] - 0.05103135108947754 sec - loss: 0.0660988911986351\n",
            "Epoch: 782/1000\n",
            "[===============================] - 0.04956197738647461 sec - loss: 0.030683383345603943\n",
            "Epoch: 783/1000\n",
            "[===============================] - 0.052301883697509766 sec - loss: 0.024980150163173676\n",
            "Epoch: 784/1000\n",
            "[===============================] - 0.050662994384765625 sec - loss: 0.023419342935085297\n",
            "Epoch: 785/1000\n",
            "[===============================] - 0.050688743591308594 sec - loss: 0.024552779272198677\n",
            "Epoch: 786/1000\n",
            "[===============================] - 0.05009651184082031 sec - loss: 0.22248603403568268\n",
            "Epoch: 787/1000\n",
            "[===============================] - 0.05496811866760254 sec - loss: 0.8549428582191467\n",
            "Epoch: 788/1000\n",
            "[===============================] - 0.04959368705749512 sec - loss: 0.2589482069015503\n",
            "Epoch: 789/1000\n",
            "[===============================] - 0.05650162696838379 sec - loss: 0.02019188553094864\n",
            "Epoch: 790/1000\n",
            "[===============================] - 0.05288839340209961 sec - loss: 0.10145170241594315\n",
            "Epoch: 791/1000\n",
            "[===============================] - 0.05189251899719238 sec - loss: 6.645543575286865\n",
            "Epoch: 792/1000\n",
            "[===============================] - 0.05305075645446777 sec - loss: 0.08414531499147415\n",
            "Epoch: 793/1000\n",
            "[===============================] - 0.049651145935058594 sec - loss: 0.3124810457229614\n",
            "Epoch: 794/1000\n",
            "[===============================] - 0.051938533782958984 sec - loss: 0.25309935212135315\n",
            "Epoch: 795/1000\n",
            "[===============================] - 0.05277228355407715 sec - loss: 0.17455445230007172\n",
            "Epoch: 796/1000\n",
            "[===============================] - 0.04988670349121094 sec - loss: 0.8993333578109741\n",
            "Epoch: 797/1000\n",
            "[===============================] - 0.050031423568725586 sec - loss: 0.6807763576507568\n",
            "Epoch: 798/1000\n",
            "[===============================] - 0.051017045974731445 sec - loss: 3.4386351108551025\n",
            "Epoch: 799/1000\n",
            "[===============================] - 0.05470108985900879 sec - loss: 0.17398591339588165\n",
            "Epoch: 800/1000\n",
            "[===============================] - 0.05258893966674805 sec - loss: 0.947812020778656\n",
            "Epoch: 801/1000\n",
            "[===============================] - 0.049594879150390625 sec - loss: 0.7413447499275208\n",
            "Epoch: 802/1000\n",
            "[===============================] - 0.05308723449707031 sec - loss: 0.12430067360401154\n",
            "Epoch: 803/1000\n",
            "[===============================] - 0.05498695373535156 sec - loss: 0.9677833318710327\n",
            "Epoch: 804/1000\n",
            "[===============================] - 0.052967071533203125 sec - loss: 3.5697085857391357\n",
            "Epoch: 805/1000\n",
            "[===============================] - 0.05346417427062988 sec - loss: 0.1827288568019867\n",
            "Epoch: 806/1000\n",
            "[===============================] - 0.052095651626586914 sec - loss: 0.7533763647079468\n",
            "Epoch: 807/1000\n",
            "[===============================] - 0.05129694938659668 sec - loss: 1.0054007768630981\n",
            "Epoch: 808/1000\n",
            "[===============================] - 0.05651140213012695 sec - loss: 0.30225780606269836\n",
            "Epoch: 809/1000\n",
            "[===============================] - 0.051788330078125 sec - loss: 2.4323229789733887\n",
            "Epoch: 810/1000\n",
            "[===============================] - 0.05455374717712402 sec - loss: 1.5091581344604492\n",
            "Epoch: 811/1000\n",
            "[===============================] - 0.05111193656921387 sec - loss: 0.11338508874177933\n",
            "Epoch: 812/1000\n",
            "[===============================] - 0.05108785629272461 sec - loss: 0.1048889085650444\n",
            "Epoch: 813/1000\n",
            "[===============================] - 0.05038928985595703 sec - loss: 0.4648851156234741\n",
            "Epoch: 814/1000\n",
            "[===============================] - 0.052228450775146484 sec - loss: 8.759167671203613\n",
            "Epoch: 815/1000\n",
            "[===============================] - 0.05500006675720215 sec - loss: 0.06367310881614685\n",
            "Epoch: 816/1000\n",
            "[===============================] - 0.052300214767456055 sec - loss: 0.07252151519060135\n",
            "Epoch: 817/1000\n",
            "[===============================] - 0.05029940605163574 sec - loss: 0.07467018067836761\n",
            "Epoch: 818/1000\n",
            "[===============================] - 0.05272269248962402 sec - loss: 0.12121982872486115\n",
            "Epoch: 819/1000\n",
            "[===============================] - 0.05019259452819824 sec - loss: 1.4859763383865356\n",
            "Epoch: 820/1000\n",
            "[===============================] - 0.050667524337768555 sec - loss: 0.109925776720047\n",
            "Epoch: 821/1000\n",
            "[===============================] - 0.05381417274475098 sec - loss: 0.08922001719474792\n",
            "Epoch: 822/1000\n",
            "[===============================] - 0.05236077308654785 sec - loss: 0.17262771725654602\n",
            "Epoch: 823/1000\n",
            "[===============================] - 0.05517148971557617 sec - loss: 7.805954456329346\n",
            "Epoch: 824/1000\n",
            "[===============================] - 0.05260348320007324 sec - loss: 0.1361430287361145\n",
            "Epoch: 825/1000\n",
            "[===============================] - 0.05176520347595215 sec - loss: 0.1054394468665123\n",
            "Epoch: 826/1000\n",
            "[===============================] - 0.05587124824523926 sec - loss: 0.08725013583898544\n",
            "Epoch: 827/1000\n",
            "[===============================] - 0.054845333099365234 sec - loss: 0.04567260295152664\n",
            "Epoch: 828/1000\n",
            "[===============================] - 0.05552816390991211 sec - loss: 0.04597385600209236\n",
            "Epoch: 829/1000\n",
            "[===============================] - 0.05329155921936035 sec - loss: 0.1245332807302475\n",
            "Epoch: 830/1000\n",
            "[===============================] - 0.055119991302490234 sec - loss: 0.4506574869155884\n",
            "Epoch: 831/1000\n",
            "[===============================] - 0.05047750473022461 sec - loss: 3.2296018600463867\n",
            "Epoch: 832/1000\n",
            "[===============================] - 0.049863576889038086 sec - loss: 0.9966372847557068\n",
            "Epoch: 833/1000\n",
            "[===============================] - 0.05304551124572754 sec - loss: 0.6946418285369873\n",
            "Epoch: 834/1000\n",
            "[===============================] - 0.05164599418640137 sec - loss: 2.521029233932495\n",
            "Epoch: 835/1000\n",
            "[===============================] - 0.05339813232421875 sec - loss: 0.06409864127635956\n",
            "Epoch: 836/1000\n",
            "[===============================] - 0.05271172523498535 sec - loss: 0.4701041281223297\n",
            "Epoch: 837/1000\n",
            "[===============================] - 0.052367448806762695 sec - loss: 1.017383098602295\n",
            "Epoch: 838/1000\n",
            "[===============================] - 0.05056309700012207 sec - loss: 0.2445107251405716\n",
            "Epoch: 839/1000\n",
            "[===============================] - 0.04977583885192871 sec - loss: 7.875158786773682\n",
            "Epoch: 840/1000\n",
            "[===============================] - 0.04927706718444824 sec - loss: 0.031536273658275604\n",
            "Epoch: 841/1000\n",
            "[===============================] - 0.05112791061401367 sec - loss: 0.05394889414310455\n",
            "Epoch: 842/1000\n",
            "[===============================] - 0.05161261558532715 sec - loss: 0.06972009688615799\n",
            "Epoch: 843/1000\n",
            "[===============================] - 0.051180362701416016 sec - loss: 0.08728933334350586\n",
            "Epoch: 844/1000\n",
            "[===============================] - 0.05010271072387695 sec - loss: 0.11384006589651108\n",
            "Epoch: 845/1000\n",
            "[===============================] - 0.05159449577331543 sec - loss: 0.21330316364765167\n",
            "Epoch: 846/1000\n",
            "[===============================] - 0.049446821212768555 sec - loss: 3.7636630535125732\n",
            "Epoch: 847/1000\n",
            "[===============================] - 0.05734825134277344 sec - loss: 0.2119787484407425\n",
            "Epoch: 848/1000\n",
            "[===============================] - 0.050576210021972656 sec - loss: 1.5480389595031738\n",
            "Epoch: 849/1000\n",
            "[===============================] - 0.06149005889892578 sec - loss: 0.13832035660743713\n",
            "Epoch: 850/1000\n",
            "[===============================] - 0.05362415313720703 sec - loss: 0.06583652645349503\n",
            "Epoch: 851/1000\n",
            "[===============================] - 0.0546419620513916 sec - loss: 0.11903933435678482\n",
            "Epoch: 852/1000\n",
            "[===============================] - 0.053071022033691406 sec - loss: 9.586857795715332\n",
            "Epoch: 853/1000\n",
            "[===============================] - 0.05481696128845215 sec - loss: 0.09904121607542038\n",
            "Epoch: 854/1000\n",
            "[===============================] - 0.05075645446777344 sec - loss: 0.08952344954013824\n",
            "Epoch: 855/1000\n",
            "[===============================] - 0.050438880920410156 sec - loss: 0.0761757418513298\n",
            "Epoch: 856/1000\n",
            "[===============================] - 0.055803775787353516 sec - loss: 0.04939998313784599\n",
            "Epoch: 857/1000\n",
            "[===============================] - 0.053313493728637695 sec - loss: 0.03247816115617752\n",
            "Epoch: 858/1000\n",
            "[===============================] - 0.052515506744384766 sec - loss: 0.7742159962654114\n",
            "Epoch: 859/1000\n",
            "[===============================] - 0.05342721939086914 sec - loss: 0.0758834183216095\n",
            "Epoch: 860/1000\n",
            "[===============================] - 0.0528872013092041 sec - loss: 0.1062462255358696\n",
            "Epoch: 861/1000\n",
            "[===============================] - 0.0502619743347168 sec - loss: 0.7160791158676147\n",
            "Epoch: 862/1000\n",
            "[===============================] - 0.051778554916381836 sec - loss: 11.013507843017578\n",
            "Epoch: 863/1000\n",
            "[===============================] - 0.05442619323730469 sec - loss: 0.04998841881752014\n",
            "Epoch: 864/1000\n",
            "[===============================] - 0.05816531181335449 sec - loss: 0.029028646647930145\n",
            "Epoch: 865/1000\n",
            "[===============================] - 0.058997154235839844 sec - loss: 0.022342843934893608\n",
            "Epoch: 866/1000\n",
            "[===============================] - 0.05099964141845703 sec - loss: 0.05362503603100777\n",
            "Epoch: 867/1000\n",
            "[===============================] - 0.05323910713195801 sec - loss: 0.9628958702087402\n",
            "Epoch: 868/1000\n",
            "[===============================] - 0.050354719161987305 sec - loss: 0.031280696392059326\n",
            "Epoch: 869/1000\n",
            "[===============================] - 0.04936957359313965 sec - loss: 0.061925098299980164\n",
            "Epoch: 870/1000\n",
            "[===============================] - 0.05081677436828613 sec - loss: 0.07159177213907242\n",
            "Epoch: 871/1000\n",
            "[===============================] - 0.058097124099731445 sec - loss: 0.015612252987921238\n",
            "Epoch: 872/1000\n",
            "[===============================] - 0.05209231376647949 sec - loss: 0.48771217465400696\n",
            "Epoch: 873/1000\n",
            "[===============================] - 0.05408906936645508 sec - loss: 8.625988006591797\n",
            "Epoch: 874/1000\n",
            "[===============================] - 0.05070328712463379 sec - loss: 0.07395818829536438\n",
            "Epoch: 875/1000\n",
            "[===============================] - 0.05478358268737793 sec - loss: 0.06347896158695221\n",
            "Epoch: 876/1000\n",
            "[===============================] - 0.0530552864074707 sec - loss: 0.065892793238163\n",
            "Epoch: 877/1000\n",
            "[===============================] - 0.05199599266052246 sec - loss: 0.14306578040122986\n",
            "Epoch: 878/1000\n",
            "[===============================] - 0.04944562911987305 sec - loss: 0.6232693195343018\n",
            "Epoch: 879/1000\n",
            "[===============================] - 0.05278801918029785 sec - loss: 0.13181664049625397\n",
            "Epoch: 880/1000\n",
            "[===============================] - 0.04963040351867676 sec - loss: 0.04182465374469757\n",
            "Epoch: 881/1000\n",
            "[===============================] - 0.050965309143066406 sec - loss: 0.46056053042411804\n",
            "Epoch: 882/1000\n",
            "[===============================] - 0.05174136161804199 sec - loss: 6.2281575202941895\n",
            "Epoch: 883/1000\n",
            "[===============================] - 0.05599164962768555 sec - loss: 0.2456827014684677\n",
            "Epoch: 884/1000\n",
            "[===============================] - 0.05743908882141113 sec - loss: 0.4747677743434906\n",
            "Epoch: 885/1000\n",
            "[===============================] - 0.05283403396606445 sec - loss: 0.2806551456451416\n",
            "Epoch: 886/1000\n",
            "[===============================] - 0.05440330505371094 sec - loss: 0.5098589658737183\n",
            "Epoch: 887/1000\n",
            "[===============================] - 0.0634467601776123 sec - loss: 0.16837385296821594\n",
            "Epoch: 888/1000\n",
            "[===============================] - 0.052907705307006836 sec - loss: 0.023762578144669533\n",
            "Epoch: 889/1000\n",
            "[===============================] - 0.053086280822753906 sec - loss: 2.7146389484405518\n",
            "Epoch: 890/1000\n",
            "[===============================] - 0.058210134506225586 sec - loss: 1.02222740650177\n",
            "Epoch: 891/1000\n",
            "[===============================] - 0.057337284088134766 sec - loss: 1.4890958070755005\n",
            "Epoch: 892/1000\n",
            "[===============================] - 0.061859846115112305 sec - loss: 0.5144797563552856\n",
            "Epoch: 893/1000\n",
            "[===============================] - 0.05070853233337402 sec - loss: 0.16230903565883636\n",
            "Epoch: 894/1000\n",
            "[===============================] - 0.05180048942565918 sec - loss: 1.6645704507827759\n",
            "Epoch: 895/1000\n",
            "[===============================] - 0.0500490665435791 sec - loss: 0.8931052684783936\n",
            "Epoch: 896/1000\n",
            "[===============================] - 0.05025935173034668 sec - loss: 5.977953910827637\n",
            "Epoch: 897/1000\n",
            "[===============================] - 0.05059385299682617 sec - loss: 0.03877735510468483\n",
            "Epoch: 898/1000\n",
            "[===============================] - 0.051911354064941406 sec - loss: 0.06210796907544136\n",
            "Epoch: 899/1000\n",
            "[===============================] - 0.052156925201416016 sec - loss: 0.1102197915315628\n",
            "Epoch: 900/1000\n",
            "[===============================] - 0.049704551696777344 sec - loss: 0.15270289778709412\n",
            "Epoch: 901/1000\n",
            "[===============================] - 0.05053138732910156 sec - loss: 0.43502795696258545\n",
            "Epoch: 902/1000\n",
            "[===============================] - 0.05153632164001465 sec - loss: 0.08817913383245468\n",
            "Epoch: 903/1000\n",
            "[===============================] - 0.05448436737060547 sec - loss: 8.534808158874512\n",
            "Epoch: 904/1000\n",
            "[===============================] - 0.05382990837097168 sec - loss: 0.06564813107252121\n",
            "Epoch: 905/1000\n",
            "[===============================] - 0.05654788017272949 sec - loss: 0.045267749577760696\n",
            "Epoch: 906/1000\n",
            "[===============================] - 0.05022835731506348 sec - loss: 0.11524882912635803\n",
            "Epoch: 907/1000\n",
            "[===============================] - 0.05057954788208008 sec - loss: 0.16318684816360474\n",
            "Epoch: 908/1000\n",
            "[===============================] - 0.049980878829956055 sec - loss: 0.10380759835243225\n",
            "Epoch: 909/1000\n",
            "[===============================] - 0.062444210052490234 sec - loss: 1.5079340934753418\n",
            "Epoch: 910/1000\n",
            "[===============================] - 0.056420326232910156 sec - loss: 0.21322615444660187\n",
            "Epoch: 911/1000\n",
            "[===============================] - 0.05105328559875488 sec - loss: 0.6025974154472351\n",
            "Epoch: 912/1000\n",
            "[===============================] - 0.053585052490234375 sec - loss: 1.7340949773788452\n",
            "Epoch: 913/1000\n",
            "[===============================] - 0.0592350959777832 sec - loss: 1.1066997051239014\n",
            "Epoch: 914/1000\n",
            "[===============================] - 0.05567002296447754 sec - loss: 2.6283109188079834\n",
            "Epoch: 915/1000\n",
            "[===============================] - 0.04972100257873535 sec - loss: 0.025860833004117012\n",
            "Epoch: 916/1000\n",
            "[===============================] - 0.05086493492126465 sec - loss: 0.5615036487579346\n",
            "Epoch: 917/1000\n",
            "[===============================] - 0.05358600616455078 sec - loss: 0.15541879832744598\n",
            "Epoch: 918/1000\n",
            "[===============================] - 0.052506446838378906 sec - loss: 1.895372986793518\n",
            "Epoch: 919/1000\n",
            "[===============================] - 0.049843549728393555 sec - loss: 1.5943968296051025\n",
            "Epoch: 920/1000\n",
            "[===============================] - 0.05550575256347656 sec - loss: 0.23508964478969574\n",
            "Epoch: 921/1000\n",
            "[===============================] - 0.05620694160461426 sec - loss: 1.7285443544387817\n",
            "Epoch: 922/1000\n",
            "[===============================] - 0.056403398513793945 sec - loss: 0.7055553197860718\n",
            "Epoch: 923/1000\n",
            "[===============================] - 0.057852983474731445 sec - loss: 1.011829137802124\n",
            "Epoch: 924/1000\n",
            "[===============================] - 0.05559945106506348 sec - loss: 1.3917473554611206\n",
            "Epoch: 925/1000\n",
            "[===============================] - 0.05284714698791504 sec - loss: 0.11717668920755386\n",
            "Epoch: 926/1000\n",
            "[===============================] - 0.05281710624694824 sec - loss: 4.11659574508667\n",
            "Epoch: 927/1000\n",
            "[===============================] - 0.05024385452270508 sec - loss: 0.46423402428627014\n",
            "Epoch: 928/1000\n",
            "[===============================] - 0.058089256286621094 sec - loss: 0.2755880653858185\n",
            "Epoch: 929/1000\n",
            "[===============================] - 0.050572872161865234 sec - loss: 0.11640763282775879\n",
            "Epoch: 930/1000\n",
            "[===============================] - 0.05271553993225098 sec - loss: 0.17186377942562103\n",
            "Epoch: 931/1000\n",
            "[===============================] - 0.05747103691101074 sec - loss: 10.452019691467285\n",
            "Epoch: 932/1000\n",
            "[===============================] - 0.056232452392578125 sec - loss: 0.15500052273273468\n",
            "Epoch: 933/1000\n",
            "[===============================] - 0.05387544631958008 sec - loss: 0.3542495369911194\n",
            "Epoch: 934/1000\n",
            "[===============================] - 0.049726009368896484 sec - loss: 0.03232153505086899\n",
            "Epoch: 935/1000\n",
            "[===============================] - 0.05296683311462402 sec - loss: 0.18449467420578003\n",
            "Epoch: 936/1000\n",
            "[===============================] - 0.05034470558166504 sec - loss: 4.816859722137451\n",
            "Epoch: 937/1000\n",
            "[===============================] - 0.05092501640319824 sec - loss: 0.09731677174568176\n",
            "Epoch: 938/1000\n",
            "[===============================] - 0.05356264114379883 sec - loss: 0.5046893358230591\n",
            "Epoch: 939/1000\n",
            "[===============================] - 0.051629066467285156 sec - loss: 0.16970017552375793\n",
            "Epoch: 940/1000\n",
            "[===============================] - 0.056339263916015625 sec - loss: 0.05544978007674217\n",
            "Epoch: 941/1000\n",
            "[===============================] - 0.04903602600097656 sec - loss: 0.02493952214717865\n",
            "Epoch: 942/1000\n",
            "[===============================] - 0.054033517837524414 sec - loss: 6.834011554718018\n",
            "Epoch: 943/1000\n",
            "[===============================] - 0.05388784408569336 sec - loss: 0.06181243807077408\n",
            "Epoch: 944/1000\n",
            "[===============================] - 0.0533750057220459 sec - loss: 0.13377444446086884\n",
            "Epoch: 945/1000\n",
            "[===============================] - 0.05257129669189453 sec - loss: 0.19189555943012238\n",
            "Epoch: 946/1000\n",
            "[===============================] - 0.05226588249206543 sec - loss: 0.2311135083436966\n",
            "Epoch: 947/1000\n",
            "[===============================] - 0.058380126953125 sec - loss: 0.1580071896314621\n",
            "Epoch: 948/1000\n",
            "[===============================] - 0.05227804183959961 sec - loss: 0.24973873794078827\n",
            "Epoch: 949/1000\n",
            "[===============================] - 0.05011868476867676 sec - loss: 5.005316734313965\n",
            "Epoch: 950/1000\n",
            "[===============================] - 0.05478930473327637 sec - loss: 0.1064222976565361\n",
            "Epoch: 951/1000\n",
            "[===============================] - 0.050548553466796875 sec - loss: 2.1937685012817383\n",
            "Epoch: 952/1000\n",
            "[===============================] - 0.05209064483642578 sec - loss: 0.17822274565696716\n",
            "Epoch: 953/1000\n",
            "[===============================] - 0.051219940185546875 sec - loss: 0.040877167135477066\n",
            "Epoch: 954/1000\n",
            "[===============================] - 0.05199122428894043 sec - loss: 0.06012975797057152\n",
            "Epoch: 955/1000\n",
            "[===============================] - 0.0496218204498291 sec - loss: 0.23617896437644958\n",
            "Epoch: 956/1000\n",
            "[===============================] - 0.05001235008239746 sec - loss: 7.841174602508545\n",
            "Epoch: 957/1000\n",
            "[===============================] - 0.05076432228088379 sec - loss: 0.07577475905418396\n",
            "Epoch: 958/1000\n",
            "[===============================] - 0.05414390563964844 sec - loss: 0.08060730993747711\n",
            "Epoch: 959/1000\n",
            "[===============================] - 0.06227302551269531 sec - loss: 0.10078943520784378\n",
            "Epoch: 960/1000\n",
            "[===============================] - 0.05339765548706055 sec - loss: 0.13993671536445618\n",
            "Epoch: 961/1000\n",
            "[===============================] - 0.05001568794250488 sec - loss: 0.19010959565639496\n",
            "Epoch: 962/1000\n",
            "[===============================] - 0.05350136756896973 sec - loss: 0.10450602322816849\n",
            "Epoch: 963/1000\n",
            "[===============================] - 0.04938220977783203 sec - loss: 0.47685593366622925\n",
            "Epoch: 964/1000\n",
            "[===============================] - 0.055405378341674805 sec - loss: 1.8646440505981445\n",
            "Epoch: 965/1000\n",
            "[===============================] - 0.052886962890625 sec - loss: 3.5887417793273926\n",
            "Epoch: 966/1000\n",
            "[===============================] - 0.05588817596435547 sec - loss: 0.13689729571342468\n",
            "Epoch: 967/1000\n",
            "[===============================] - 0.049278974533081055 sec - loss: 0.17052826285362244\n",
            "Epoch: 968/1000\n",
            "[===============================] - 0.050171613693237305 sec - loss: 0.015246703289449215\n",
            "Epoch: 969/1000\n",
            "[===============================] - 0.04991745948791504 sec - loss: 0.5552497506141663\n",
            "Epoch: 970/1000\n",
            "[===============================] - 0.055817365646362305 sec - loss: 7.528029441833496\n",
            "Epoch: 971/1000\n",
            "[===============================] - 0.05186271667480469 sec - loss: 0.11341886967420578\n",
            "Epoch: 972/1000\n",
            "[===============================] - 0.05045652389526367 sec - loss: 0.12509562075138092\n",
            "Epoch: 973/1000\n",
            "[===============================] - 0.05118274688720703 sec - loss: 0.09298928827047348\n",
            "Epoch: 974/1000\n",
            "[===============================] - 0.05649733543395996 sec - loss: 0.06289598345756531\n",
            "Epoch: 975/1000\n",
            "[===============================] - 0.05084562301635742 sec - loss: 0.0952092781662941\n",
            "Epoch: 976/1000\n",
            "[===============================] - 0.05522584915161133 sec - loss: 0.28778597712516785\n",
            "Epoch: 977/1000\n",
            "[===============================] - 0.05712151527404785 sec - loss: 0.17563356459140778\n",
            "Epoch: 978/1000\n",
            "[===============================] - 0.05543971061706543 sec - loss: 9.907288551330566\n",
            "Epoch: 979/1000\n",
            "[===============================] - 0.053202152252197266 sec - loss: 0.04976360499858856\n",
            "Epoch: 980/1000\n",
            "[===============================] - 0.05426335334777832 sec - loss: 0.03370596095919609\n",
            "Epoch: 981/1000\n",
            "[===============================] - 0.056592464447021484 sec - loss: 0.02675388567149639\n",
            "Epoch: 982/1000\n",
            "[===============================] - 0.049710750579833984 sec - loss: 0.024156620725989342\n",
            "Epoch: 983/1000\n",
            "[===============================] - 0.05133700370788574 sec - loss: 0.024750584736466408\n",
            "Epoch: 984/1000\n",
            "[===============================] - 0.05170321464538574 sec - loss: 0.023906130343675613\n",
            "Epoch: 985/1000\n",
            "[===============================] - 0.060317039489746094 sec - loss: 0.015728991478681564\n",
            "Epoch: 986/1000\n",
            "[===============================] - 0.052671194076538086 sec - loss: 0.07329777628183365\n",
            "Epoch: 987/1000\n",
            "[===============================] - 0.052980661392211914 sec - loss: 5.245895862579346\n",
            "Epoch: 988/1000\n",
            "[===============================] - 0.05128788948059082 sec - loss: 0.07917432487010956\n",
            "Epoch: 989/1000\n",
            "[===============================] - 0.05292391777038574 sec - loss: 0.5705651640892029\n",
            "Epoch: 990/1000\n",
            "[===============================] - 0.05023050308227539 sec - loss: 0.6112069487571716\n",
            "Epoch: 991/1000\n",
            "[===============================] - 0.04900670051574707 sec - loss: 0.12345851212739944\n",
            "Epoch: 992/1000\n",
            "[===============================] - 0.0497591495513916 sec - loss: 0.08575263619422913\n",
            "Epoch: 993/1000\n",
            "[===============================] - 0.05100727081298828 sec - loss: 7.0651936531066895\n",
            "Epoch: 994/1000\n",
            "[===============================] - 0.04982757568359375 sec - loss: 0.07444509118795395\n",
            "Epoch: 995/1000\n",
            "[===============================] - 0.05016970634460449 sec - loss: 0.11528269946575165\n",
            "Epoch: 996/1000\n",
            "[===============================] - 0.055428504943847656 sec - loss: 0.1493017077445984\n",
            "Epoch: 997/1000\n",
            "[===============================] - 0.05350136756896973 sec - loss: 0.1723121553659439\n",
            "Epoch: 998/1000\n",
            "[===============================] - 0.05115342140197754 sec - loss: 0.08474113792181015\n",
            "Epoch: 999/1000\n",
            "[===============================] - 0.05030512809753418 sec - loss: 0.08690354973077774\n",
            "Epoch: 1000/1000\n",
            "[===============================] - 0.05380845069885254 sec - loss: 3.1947836875915527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqJMre6D-4TJ"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiR1k19dzyak",
        "outputId": "ab90c306-9747-4c98-b641-ac898533ae1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(['x', 'y', 'expected', 'actual'])\n",
        "print(np.concatenate((data[800:810], data_labels[800:810], predict(data[800:810], 5)), axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['x', 'y', 'expected', 'actual']\n",
            "[[ 33.       68.      101.      101.03841]\n",
            " [ 17.       13.       30.       30.01556]\n",
            " [ 35.       96.      131.      131.06386]\n",
            " [ 36.       62.       98.       98.03688]\n",
            " [ 65.       26.       91.       91.10667]\n",
            " [ 57.       87.      144.      144.0733 ]\n",
            " [ 78.       77.      155.      155.11429]\n",
            " [  7.       85.       92.       92.05056]\n",
            " [ 45.       33.       78.       78.07259]\n",
            " [ 34.       84.      118.      118.05524]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wHPRONEGV-L",
        "outputId": "488861ad-27f9-41af-986f-2a3e9d9a3860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.semilogy(fitres['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1DFcorH4_-1"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1sYPTAdNQoU"
      },
      "source": [
        "#c = compute(data[800:810], 6)\n",
        "#for b in tf.unstack(c, axis=0):\n",
        "#  for it in tf.unstack(b, axis=0):\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x4yhkHx5EOx",
        "outputId": "b5617475-4c1b-451c-d4a9-84909893f152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(compute(data[800:810], 6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 9.9878569e+00  1.0103841e+02]\n",
            "  [ 2.1664500e-03  2.6570940e+00]\n",
            "  [ 2.2638440e-03  8.1952083e-01]\n",
            "  [ 8.3869696e-04  6.6641688e-01]\n",
            "  [ 5.9407949e-04  6.6178602e-01]\n",
            "  [ 7.7921152e-04  6.6151106e-01]]\n",
            "\n",
            " [[ 1.0017448e+01  3.0015560e+01]\n",
            "  [-1.5600920e-03  1.1182870e+00]\n",
            "  [-2.1404028e-04  6.5373570e-01]\n",
            "  [ 7.3671341e-04  6.6051042e-01]\n",
            "  [ 1.0154247e-03  6.6144168e-01]\n",
            "  [ 7.3564053e-04  6.6150486e-01]]\n",
            "\n",
            " [[ 1.0020744e+01  1.3106386e+02]\n",
            "  [ 4.9233437e-05  3.4401510e+00]\n",
            "  [ 2.5045872e-03  9.5143670e-01]\n",
            "  [ 8.5759163e-04  6.7025167e-01]\n",
            "  [ 3.5983324e-04  6.6181201e-01]\n",
            "  [ 7.9071522e-04  6.6154087e-01]]\n",
            "\n",
            " [[ 1.0016863e+01  9.8036880e+01]\n",
            "  [ 4.8911572e-03  2.5353591e+00]\n",
            "  [ 1.5535355e-03  8.0410814e-01]\n",
            "  [ 6.6345930e-04  6.6608417e-01]\n",
            "  [ 6.2072277e-04  6.6177487e-01]\n",
            "  [ 7.7491999e-04  6.6151017e-01]]\n",
            "\n",
            " [[ 1.0039879e+01  9.1106667e+01]\n",
            "  [ 6.8730116e-04  2.3943162e+00]\n",
            "  [-3.4111738e-04  7.6752341e-01]\n",
            "  [ 5.1492453e-04  6.6470307e-01]\n",
            "  [ 7.0643425e-04  6.6175276e-01]\n",
            "  [ 7.6472759e-04  6.6150486e-01]]\n",
            "\n",
            " [[ 1.0014872e+01  1.4407330e+02]\n",
            "  [ 6.0484409e-03  3.4657648e+00]\n",
            "  [ 2.5246143e-03  9.6724832e-01]\n",
            "  [ 6.5231323e-04  6.7093509e-01]\n",
            "  [ 3.4397840e-04  6.6180509e-01]\n",
            "  [ 7.8856945e-04  6.6154641e-01]]\n",
            "\n",
            " [[ 1.0019323e+01  1.5511429e+02]\n",
            "  [ 1.3190508e-03  3.6210353e+00]\n",
            "  [ 9.2679262e-04  9.9303532e-01]\n",
            "  [ 2.8145313e-04  6.7197758e-01]\n",
            "  [ 3.0183792e-04  6.6180426e-01]\n",
            "  [ 7.8767538e-04  6.6155422e-01]]\n",
            "\n",
            " [[ 9.9672422e+00  9.2050560e+01]\n",
            "  [ 1.7198324e-03  2.9445755e+00]\n",
            "  [-5.3656101e-04  8.4677541e-01]\n",
            "  [ 2.8228760e-04  6.6787905e-01]\n",
            "  [ 5.3679943e-04  6.6178548e-01]\n",
            "  [ 7.7712536e-04  6.6152239e-01]]\n",
            "\n",
            " [[ 9.9724388e+00  7.8072594e+01]\n",
            "  [ 8.0001354e-04  2.0505729e+00]\n",
            "  [ 1.0727644e-03  7.3335075e-01]\n",
            "  [ 4.0197372e-04  6.6364849e-01]\n",
            "  [ 8.0120564e-04  6.6172314e-01]\n",
            "  [ 7.5095892e-04  6.6150242e-01]]\n",
            "\n",
            " [[ 1.0017523e+01  1.1805524e+02]\n",
            "  [-4.3374300e-04  3.1015353e+00]\n",
            "  [ 1.7848015e-03  8.9167333e-01]\n",
            "  [ 1.1527538e-03  6.6798997e-01]\n",
            "  [ 4.5996904e-04  6.6181529e-01]\n",
            "  [ 7.9119205e-04  6.6152203e-01]]], shape=(10, 6, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_1NCm-uCktQ",
        "outputId": "c1bde5a0-3cc5-42a5-f1be-3cda17452555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "predict(data[800:810], 6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[101.03841],\n",
              "       [ 30.01556],\n",
              "       [131.06386],\n",
              "       [ 98.03688],\n",
              "       [ 91.10667],\n",
              "       [144.0733 ],\n",
              "       [155.11429],\n",
              "       [ 92.05056],\n",
              "       [ 78.07259],\n",
              "       [118.05524]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    }
  ]
}